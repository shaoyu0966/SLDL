{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Learning and Deep Learning, 2020 Fall\n",
    "### Homework 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1\n",
    "First, read the training data and the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['capital-loss', 'hours-per-week', 'capital-gain', 'educational-num',\n",
      "       'age', 'fnlwgt', 'relationship', 'race', 'gender', 'occupation',\n",
      "       'education', 'native-country', 'workclass', 'marital-status', 'income'],\n",
      "      dtype='object')\n",
      "Index(['capital-loss', 'hours-per-week', 'capital-gain', 'educational-num',\n",
      "       'age', 'fnlwgt', 'relationship', 'race', 'gender', 'occupation',\n",
      "       'education', 'native-country', 'workclass', 'marital-status', 'income'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# read data\n",
    "train = pd.read_csv('adult.data', header=None)\n",
    "test = pd.read_csv('adult.test', header=None)\n",
    "\n",
    "# assign column names\n",
    "col_name = ['age', 'workclass', 'fnlwgt', 'education', 'educational-num', \n",
    "           'marital-status', 'occupation', 'relationship', 'race', 'gender', \n",
    "           'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income']\n",
    "train.columns = col_name\n",
    "test.columns = col_name\n",
    "\n",
    "# reorder columns\n",
    "col_sequence = ['capital-loss', 'hours-per-week', 'capital-gain', 'educational-num', 'age', 'fnlwgt', \n",
    "              'relationship', 'race', 'gender', 'occupation', 'education', 'native-country', 'workclass', \n",
    "               'marital-status', 'income']\n",
    "train = train[col_sequence]\n",
    "test = test[col_sequence]\n",
    "print(train.columns)\n",
    "print(test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, remove NaNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape (30162, 15)\n",
      "test shape (15060, 15)\n"
     ]
    }
   ],
   "source": [
    "train = train.replace(' ?', np.NaN).dropna()\n",
    "test = test.replace(' ?', np.NaN).dropna()\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "test.reset_index(drop=True, inplace=True)\n",
    "print('train shape', train.shape)\n",
    "print('test shape', test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split $x$, $y$. Convert '>50K' and '<=50K' into 1 and 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: (30162, 14)\n",
      "y_train: (30162, 1)\n",
      "x_test: (15060, 14)\n",
      "y_test: (15060, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train = train.iloc[:, :-1]\n",
    "y_train = train.iloc[:, -1:]\n",
    "x_test = test.iloc[:, :-1]\n",
    "y_test = test.iloc[:, -1:]\n",
    "\n",
    "convert_train = {' >50K': 1, ' <=50K': 0}\n",
    "convert_test = {' >50K.': 1, ' <=50K.': 0}\n",
    "y_train['income'] = y_train['income'].map(convert_train)\n",
    "y_test['income'] = y_test['income'].map(convert_test)\n",
    "print(f'x_train: {x_train.shape}')\n",
    "print(f'y_train: {y_train.shape}')\n",
    "print(f'x_test: {x_test.shape}')\n",
    "print(f'y_test: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all categorical features, apply 1-of-K encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_cat shape:  (30162, 98)\n",
      "x_train_num shape:  (30162, 6)\n",
      "x_test_cat shape:  (15060, 97)\n",
      "x_test_num shape:  (15060, 6)\n"
     ]
    }
   ],
   "source": [
    "x_train_cat = x_train.select_dtypes(include='object')\n",
    "x_train_num = x_train.select_dtypes(include='int64')\n",
    "x_test_cat = x_test.select_dtypes(include='object')\n",
    "x_test_num = x_test.select_dtypes(include='int64')\n",
    "\n",
    "x_train_cat = pd.get_dummies(x_train_cat)\n",
    "x_train_cat.columns = x_train_cat.columns.str.replace(' ', '')\n",
    "x_test_cat = pd.get_dummies(x_test_cat)\n",
    "x_test_cat.columns = x_test_cat.columns.str.replace(' ', '')\n",
    "print('x_train_cat shape: ', x_train_cat.shape)\n",
    "print('x_train_num shape: ', x_train_num.shape)\n",
    "print('x_test_cat shape: ', x_test_cat.shape)\n",
    "print('x_test_num shape: ', x_test_num.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove features that appeared less than 10 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_cat shape:  (30162, 96)\n",
      "x_test_cat shape:  (15060, 96)\n"
     ]
    }
   ],
   "source": [
    "x_train_cat = x_train_cat[x_train_cat.columns[x_train_cat.sum() >= 10]]\n",
    "x_test_cat = x_test_cat[x_train_cat.columns]\n",
    "print('x_train_cat shape: ', x_train_cat.shape)\n",
    "print('x_test_cat shape: ', x_test_cat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_val = x_train_num.to_numpy()\n",
    "x_scaler = preprocessing.StandardScaler().fit(x_train_val)\n",
    "x_train_val = x_scaler.transform(x_train_val)\n",
    "x_train_num = pd.DataFrame(data=x_train_val, columns=x_train_num.columns)\n",
    "\n",
    "x_test_val = x_scaler.transform(x_test_num.to_numpy())\n",
    "x_test_num = pd.DataFrame(data=x_test_val, columns=x_test_num.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine data into dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult50 = {}\n",
    "adult50['num_col'] = x_train_num.columns.to_list()\n",
    "x_train = pd.concat([x_train_num, x_train_cat], axis=1)\n",
    "x_test = pd.concat([x_test_num, x_test_cat], axis=1)\n",
    "adult50['x_train'] = x_train.to_numpy()\n",
    "adult50['x_test'] = x_test.to_numpy()\n",
    "adult50['y_train'] = np.reshape(y_train.to_numpy(), (1, -1))\n",
    "adult50['y_test'] = np.reshape(y_test.to_numpy(), (1, -1))\n",
    "adult50['columnname'] = x_train.columns.tolist()\n",
    "adult50['num_col'] = x_train_num.columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare our result with `adult_m50k.pickle`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test dictionary keys:  True\n",
      "test columnname:  [ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True]\n",
      "test num_col:  True\n",
      "x_train match!\n",
      "x_test match!\n",
      "y_train match!\n",
      "y_test match!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "dsfile = 'adult_m50k.pickle'\n",
    "with open(dsfile, 'rb') as fh1:\n",
    "    adult50kp = pickle.load(fh1)\n",
    "\n",
    "print('test dictionary keys: ', adult50kp.keys() == adult50.keys())\n",
    "print('test columnname: ', adult50kp['columnname'] == adult50['columnname'])\n",
    "print('test num_col: ', adult50kp['num_col'] == adult50['num_col'])\n",
    "\n",
    "elems = ['x_train', 'x_test', 'y_train', 'y_test']\n",
    "for aelem in elems:\n",
    "    cnomatch = np.sum(adult50kp[aelem] != adult50[aelem])\n",
    "    if cnomatch == 0:\n",
    "        print(aelem, \"match!\")\n",
    "    else:\n",
    "        print(aelem, \"%d elements no match!\" % cnomatch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.848406\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# load dataset\n",
    "dsfile = 'adult_m50k.pickle'\n",
    "with open(dsfile, 'rb') as fh1:\n",
    "    adult50kp = pickle.load(fh1)\n",
    "    \n",
    "# train prediction model\n",
    "c = 0.3\n",
    "lr2 = LogisticRegression(solver = 'lbfgs', C= c, max_iter = 1000)\n",
    "lr2.fit(adult50kp['x_train'], adult50kp['y_train'])\n",
    "\n",
    "# make prediction\n",
    "ypred = lr2.predict(adult50kp['x_test'])\n",
    "ypredprob = lr2.predict_proba(adult50kp['x_test'])\n",
    "\n",
    "# compute accuracy\n",
    "ncorrect = np.sum(adult50kp['y_test'] == ypred)\n",
    "accuracy_sk = ncorrect / adult50kp['y_test'].shape[0]\n",
    "print(\"Accuracy = %f\" % accuracy_sk)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2.1\n",
    "Plot ROC curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x12c6190d0>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define TP and FP\n",
    "def TP(pred, actual):\n",
    "    # TP = TP / P\n",
    "    assert(pred.shape == actual.shape)\n",
    "    n_data = pred.shape[0]\n",
    "    p = n_data - np.sum(actual)\n",
    "    tp = np.sum(np.logical_and(actual == [0]*n_data, pred == [0]*n_data))\n",
    "    return (tp / p)\n",
    "    \n",
    "def FP(pred, actual):\n",
    "    # FP = FP / N\n",
    "    assert(pred.shape == actual.shape)\n",
    "    n_data = pred.shape[0]\n",
    "    n = np.sum(actual)\n",
    "    fp = np.sum(np.logical_and(actual == [1]*n_data, pred == [0]*n_data))\n",
    "    return(fp / n)\n",
    "\n",
    "\n",
    "# compute TP and FP under different threshold\n",
    "pos_prob = ypredprob[:, 0]\n",
    "all_prob = np.sort(np.append(pos_prob, [0, 1]))\n",
    "\n",
    "fp_rate = []\n",
    "tp_rate = []\n",
    "for thres in all_prob:\n",
    "    above_thres = list(map(lambda p: 0 if p > thres else 1, pos_prob))\n",
    "    above_thres = np.array(above_thres)\n",
    "    fpr = FP(above_thres, adult50kp['y_test'])\n",
    "    tpr = TP(above_thres, adult50kp['y_test'])\n",
    "    fp_rate.append(fpr)\n",
    "    tp_rate.append(tpr)\n",
    "\n",
    "# plot\n",
    "plt.title('ROC curve')\n",
    "plt.xlabel('FP')\n",
    "plt.ylabel('TP')\n",
    "plt.ylim(0, 1)\n",
    "plt.xlim(0, 1)\n",
    "plt.plot(fp_rate, tp_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2.2\n",
    "Compute AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC = 0.9034916373239368\n"
     ]
    }
   ],
   "source": [
    "assert(len(fp_rate) == len(tp_rate))\n",
    "n_observ = len(fp_rate)\n",
    "fp_rate.reverse()\n",
    "tp_rate.reverse()\n",
    "auc = 0\n",
    "for i in range(1, n_observ):\n",
    "    auc += (tp_rate[i-1]+tp_rate[i]) * (fp_rate[i]-fp_rate[i-1]) / 2\n",
    "print(f'AUC = {auc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3\n",
    "\n",
    "#### Q3.1\n",
    "$E(w) = \\frac{1}{2} w^T \\Lambda w - \\sum_{i=1}^n [ t_i \\ln y_i  + (1 - t_i) \\ln (1 - y_i)]$, where $y_i = \\frac{1}{1 + exp({-w^T x_i})}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\begin{align}\n",
    "\\nabla E(w)\n",
    "&= \\frac{\\partial E(w)}{\\partial w} \\\\\n",
    "&= {1 \\over 2} \\cdot \\frac{\\partial w^T \\Lambda w}{\\partial w} - \\sum_{i=1}^n \\frac{\\partial t_i \\ln y_i}{\\partial w} - \\sum_{i=1}^n \\frac{\\partial (1-t_i) \\ln (1-y_i)}{\\partial w}\n",
    "\\end{align}$\n",
    "\n",
    "Let $z_1 = \\frac{\\partial w^T \\Lambda w}{\\partial w}$, $z_2 = \\sum_{i=1}^n \\frac{\\partial t_i \\ln y_i}{\\partial w}$, $z_3 = \\sum_{i=1}^n \\frac{\\partial (1-t_i) \\ln (1-y_i)}{\\partial w}$.\n",
    "\n",
    "$\\nabla E(w)$ can then be decomposed into ${1\\over2}z_1 - z_2 - z_3$.\n",
    "\n",
    "We compute the three components in the following.\n",
    "\n",
    "$\\begin{align}\n",
    "z_1\n",
    "&= \\frac{\\partial w^T \\Lambda w}{\\partial w} \\\\\n",
    "&= 2\\Lambda w\n",
    "\\end{align}$\n",
    "\n",
    "$\\begin{align}\n",
    "z_2\n",
    "&= \\sum_{i=1}^n t_i \\cdot \\frac{\\partial \\ln y_i}{\\partial w} \\\\\n",
    "&= \\sum_{i=1}^n \\frac{t_i \\partial \\ln \\sigma(w^Tx_i)}{\\partial w} \\\\\n",
    "&= \\sum_{i=1}^n \\frac{t_i}{\\sigma(w^Tx_i)} \\cdot \\frac{\\partial \\sigma(w^Tx_i)}{\\partial w} \\\\\n",
    "&= \\sum_{i=1}^n \\frac{t_i}{\\sigma(w^Tx_i)} \\cdot \\sigma(w^Tx_i)(1 - \\sigma(w^Tx_i)) \\cdot \\frac{\\partial w^T x_i}{\\partial w} \\\\\n",
    "&= \\sum_{i=1}^n \\frac{t_i \\sigma(w^Tx_i)(1 - \\sigma(w^Tx_i)) x_i}{\\sigma(w^Tx_i)} \\\\\n",
    "&= \\sum_{i=1}^n t_i[1 - \\sigma(w^Tx_i)] x_i \\\\\n",
    "\\end{align}$\n",
    "\n",
    "$\\begin{align}\n",
    "z_3\n",
    "&= \\sum_{i=1}^n \\frac{\\partial (1-t_i) \\ln (1-y_i)}{\\partial w} \\\\\n",
    "&= \\sum_{i=1}^n (1-t_i) \\cdot \\frac{\\partial \\ln [1-\\sigma(w^Tx_i)]}{\\partial w} \\\\\n",
    "&= \\sum_{i=1}^n \\frac{1-t_i}{1-\\sigma(w^Tx_i)} \\cdot \\frac{\\partial (1 - \\sigma(w^Tx_i))}{\\partial w} \\\\\n",
    "&= \\sum_{i=1}^n \\frac{t_i - 1}{1-\\sigma(w^Tx_i)} \\cdot \\frac{\\partial \\sigma(w^Tx_i)}{\\partial w} \\\\\n",
    "&= \\sum_{i=1}^n \\frac{t_i - 1}{1-\\sigma(w^Tx_i)} \\cdot \\sigma(w^Tx_i)(1 - \\sigma(w^Tx_i)) \\cdot \\frac{\\partial w^T x_i}{\\partial w} \\\\\n",
    "&= \\sum_{i=1}^n \\frac{t_i - 1}{1-\\sigma(w^Tx_i)} \\cdot \\sigma(w^Tx_i)(1 - \\sigma(w^Tx_i)) \\cdot x_i \\\\\n",
    "&= \\sum_{i=1}^n (t_i - 1) \\cdot \\sigma(w^Tx_i) x_i \\\\\n",
    "\\end{align}$\n",
    "\n",
    "$\\begin{align}\n",
    "\\nabla E(w)\n",
    "&= {1\\over2}z_1 - z_2 - z_3 \\\\\n",
    "&= \\frac{1}{2} \\cdot 2\\Lambda w - \\sum_{i=1}^n t_i[1 - \\sigma(w^Tx_i)] x_i - \\sum_{i=1}^n (t_i - 1) \\cdot \\sigma(w^Tx_i) x_i \\\\\n",
    "&= \\Lambda w - \\sum_{i=1}^n (t_i - \\sigma(w^Tx_i)) x_i \\\\\n",
    "&= \\Lambda w - \\sum_{i=1}^n (t_i - y_i) x_i \\\\\n",
    "&= \\Lambda w - X^T(t - y) \\\\\n",
    "\\end{align}$\n",
    "\n",
    "where the i-th element in $y$, $y_i = \\sigma(w^Tx_i) = \\frac{1}{1 + exp({-w^T x_i})}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hessian matrix\n",
    "\n",
    "$\\begin{align}\n",
    "H &= \\nabla \\nabla E(w) \\\\\n",
    "&= \\frac{\\partial (\\Lambda w - \\sum_{i=1}^n (t_i - y_i) x_i)}{\\partial w} \\\\\n",
    "&= \\Lambda - \\sum_{i=1}^n \\frac{\\partial ((t_i - \\sigma(w^T x_i))x_i)}{\\partial w} \\\\\n",
    "&= \\Lambda + \\sum_{i=1}^n \\frac{\\partial (\\sigma(w^T x_i)x_i)}{\\partial w} \\\\\n",
    "&= \\Lambda + \\sum_{i=1}^n \\sigma(w^T x_i)(1-\\sigma(w^T x_i)) \\cdot \\frac{\\partial w^T x_i}{\\partial w} \\cdot x_i  \\\\\n",
    "&= \\Lambda + \\sum_{i=1}^n \\sigma(w^T x_i)(1-\\sigma(w^T x_i)) \\cdot x_i^2  \\\\\n",
    "&= \\Lambda + \\sum_{i=1}^n y_i(1-y_i) \\cdot x_i^2  \\\\\n",
    "&= \\Lambda + X^T R X\n",
    "\\end{align}$\n",
    "\n",
    "where $R$ is a $D \\times D$ diagonal matrix with elements $R_{i, i} = y_i(1-y_i)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3.2\n",
    "#### Implement `mylogistic_l2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from scipy.special import expit\n",
    "\n",
    "class mylogistic_l2():\n",
    "    \n",
    "    def __init__(self, reg_vec, max_iter=100, tol=1e-5, add_intercept=True):\n",
    "        \"\"\"\n",
    "        reg_vec: the regularization coefficient vector\n",
    "        max_iter: maximum number of iteration to run for the Newton method\n",
    "        tol: tolerance for the objective function\n",
    "        add_intercept: whether to add intercept (a column of ones) at last column of the feature matrix\n",
    "        \"\"\"\n",
    "        self.reg_vec = reg_vec\n",
    "        self.lam_mat = np.diagflat(self.reg_vec)\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.add_intercept = True\n",
    "\n",
    "    def fit(self, x, t, verbal=False):\n",
    "        n_data = t.shape[0]\n",
    "        n_feature = x.shape[1]\n",
    "        \n",
    "        # add intercept if required\n",
    "        if self.add_intercept:\n",
    "            x = np.insert(x, n_feature, 1, axis=1)\n",
    "            n_feature += 1\n",
    "        \n",
    "        # init w with ridge regression\n",
    "        b = np.mean(self.reg_vec)\n",
    "        inv_term = (x.T @ x) + b * np.eye(n_feature)\n",
    "        self.w = np.linalg.inv(inv_term) @ x.T @ t\n",
    "        \n",
    "        # update w with the Newton-Raphson method\n",
    "        prev_loss = np.Inf\n",
    "        for i in range(self.max_iter):\n",
    "            grad = self.__gradient(x, t, self.w)\n",
    "            hessian = self.__hessian(x, t, self.w)\n",
    "            self.w = self.w - np.linalg.inv(hessian) @ grad\n",
    "            loss = self.__loss(x, t, self.w)\n",
    "            \n",
    "            # print message\n",
    "            if verbal:\n",
    "                print(f'iteration {i}: {loss}')\n",
    "            \n",
    "            # check tolerance\n",
    "            if prev_loss - loss < self.tol:\n",
    "                break\n",
    "            \n",
    "            prev_loss = loss\n",
    "            \n",
    "        return prev_loss\n",
    "            \n",
    "\n",
    "    def predict(self, x):\n",
    "        if self.add_intercept:\n",
    "            x = np.insert(x, x.shape[1], 1, axis=1)\n",
    "        y = expit(x @ self.w)\n",
    "        return np.where(y > 0.5, 1, 0)\n",
    "\n",
    "    def __gradient(self, x, t, w):\n",
    "        y = expit(x @ w)\n",
    "        return self.lam_mat @ w - x.T @ (t - y)\n",
    "\n",
    "    def __hessian(self, x, t, w):\n",
    "        y = expit(x @ w)\n",
    "        r_diag = np.array([y_i * (1 - y_i) for y_i in y])\n",
    "        r = np.diagflat(r_diag)\n",
    "        return self.lam_mat + x.T @ r @ x\n",
    "    \n",
    "    def __loss(self, x, t, w):\n",
    "        y = expit(x @ w)\n",
    "        ln_y = np.log(y)\n",
    "        ln_1_y = np.log(1 - y)\n",
    "        return (w.T @ self.lam_mat @ w / 2) - (t.T @ ln_y) - ((1-t).T @ ln_1_y)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test\n",
    "\n",
    "First, read the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsfile = 'adult_m50k.pickle'\n",
    "with open(dsfile, 'rb') as fh1:\n",
    "    adult50kp = pickle.load(fh1)\n",
    "    \n",
    "x_train = adult50kp['x_train']\n",
    "y_train = adult50kp['y_train']\n",
    "x_test = adult50kp['x_test']\n",
    "y_test = adult50kp['y_test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case 1: lambda = 1 for all coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0: 11774.187058373574\n",
      "iteration 1: 10290.20488679521\n",
      "iteration 2: 9847.447046164438\n",
      "iteration 3: 9778.796798615136\n",
      "iteration 4: 9775.277416363426\n",
      "iteration 5: 9775.247127751614\n",
      "iteration 6: 9775.247122461304\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lambda_vec = np.ones(x_train.shape[1] + 1)\n",
    "logic1 = mylogistic_l2(reg_vec=lambda_vec, max_iter=1000, tol=1e-5, add_intercept=True)\n",
    "logic1.fit(x_train, y_train, verbal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w = [ 2.58310749e-01  3.52951378e-01  2.33390152e+00  7.51145211e-01\n",
      "  3.33524430e-01  7.92368680e-02 -2.59305992e-01 -3.31059192e-02\n",
      " -8.02092312e-01 -1.16328375e+00 -1.57480268e-01  1.06974336e+00\n",
      " -6.33846058e-01  1.16732409e-01 -2.31567381e-01 -5.17122207e-01\n",
      " -7.97216465e-02 -1.09949780e+00 -2.46027086e-01  6.19694928e-02\n",
      "  1.26685884e-01  8.62656059e-01 -9.18352843e-01 -6.21226177e-01\n",
      " -2.00740224e-01 -7.51600981e-01 -1.61011588e+00  5.75820911e-01\n",
      "  6.48995283e-01  3.53741434e-01  7.17218474e-01 -2.84494743e-02\n",
      " -9.54820746e-04 -1.96540899e-01 -1.46351640e-01  6.26946275e-01\n",
      "  4.48207080e-01  2.45945819e-02  4.69223657e-02 -4.91067746e-01\n",
      " -2.03035424e-01 -1.63303680e-01 -1.76623501e-02 -1.11328323e-01\n",
      " -9.94618240e-02 -1.17391916e+00  1.80702678e-01 -6.92720004e-02\n",
      "  9.76496905e-01  4.60988601e-01 -4.95440416e-01 -1.27203531e+00\n",
      "  4.86772406e-01 -8.98963733e-01 -6.00542591e-02 -3.50848853e-01\n",
      "  4.32815220e-01  5.94120150e-01  5.82151924e-01 -6.20962283e-01\n",
      " -5.97480378e-02  9.29035250e-02 -1.51892101e-01 -5.38528893e-03\n",
      "  3.41609087e-02 -2.89088236e-01  1.56053911e-01  4.95401243e-01\n",
      "  8.90942264e-01  1.49151436e-01  3.42484779e-01 -3.13312160e-01\n",
      " -3.55939108e-01 -3.62494608e-01 -6.67247475e-01 -4.08831130e-01\n",
      "  4.47489832e-01  1.37768931e-01  1.41351233e-01 -1.16015421e-01\n",
      " -5.61032710e-02 -9.34583042e-01 -2.92596523e-02 -2.99012958e-01\n",
      " -1.50511251e-01  3.52331870e-01 -7.85846536e-01  5.80200207e-01\n",
      "  4.97042311e-01 -1.90320740e-01 -3.47717245e-04  1.74993805e-01\n",
      " -4.88202695e-01 -3.12259616e-01 -1.02643023e+00 -7.22310834e-01\n",
      "  1.44672469e+00  1.15520745e+00 -6.80202902e-01 -1.21195630e+00\n",
      " -7.98338505e-01 -5.34648484e-01 -1.34552489e+00]\n",
      "accuracy = 0.847875166002656\n"
     ]
    }
   ],
   "source": [
    "# results\n",
    "def acc(act, pred):\n",
    "    n_correct = np.sum(act == pred)\n",
    "    n_data = act.shape[0]\n",
    "    return (n_correct / n_data)\n",
    "\n",
    "y_pred = logic1.predict(x_test)\n",
    "print(f'w = {logic1.w}')\n",
    "print(f'accuracy = {acc(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case 2: lambda = 1 for all but the intercept, no regularization for intercept term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0: 11773.646625265605\n",
      "iteration 1: 10288.997557988638\n",
      "iteration 2: 9845.652602749884\n",
      "iteration 3: 9776.708278538063\n",
      "iteration 4: 9773.142479313192\n",
      "iteration 5: 9773.111189226107\n",
      "iteration 6: 9773.111183558525\n"
     ]
    }
   ],
   "source": [
    "# fit\n",
    "lambda_vec = np.ones(x_train.shape[1] + 1)\n",
    "lambda_vec[-1] = 0\n",
    "logic1 = mylogistic_l2(reg_vec=lambda_vec, max_iter=1000, tol=1e-5, add_intercept=True)\n",
    "logic1.fit(x_train, y_train, verbal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w = [ 0.25833063  0.35307341  2.33348255  0.7378757   0.33385106  0.07926886\n",
      " -0.04219572  0.1998764  -0.58360968 -0.93671312  0.07548468  1.28715744\n",
      " -0.37140327  0.39422898  0.04305748 -0.26147348  0.19559029 -0.42695771\n",
      "  0.42695771  0.16424528  0.22840772  0.96472553 -0.81743779 -0.52074423\n",
      " -0.09910239 -0.64944042 -1.55235098  0.6786798   0.75066429  0.45541098\n",
      "  0.81857112  0.07308911  0.0728464  -0.11752644 -0.06282948  0.67242506\n",
      "  0.5040869   0.08799091  0.11435013 -0.38483984 -0.10196309 -0.05145374\n",
      "  0.10741777 -0.01997934  0.01717544 -1.16567808  0.30082277  0.02715464\n",
      "  1.00831207  0.50210397 -0.45756662 -1.24002555  0.52780939 -0.86832688\n",
      " -0.02771494 -0.31412701  0.47343435  0.62981111  0.62405658 -0.5867506\n",
      " -0.0296708   0.12414401 -0.14376238  0.02434194  0.0621604  -0.24843986\n",
      "  0.19459429  0.52620501  0.93165615  0.18707696  0.37950109 -0.28749402\n",
      " -0.31137357 -0.33290534 -0.65117786 -0.38160106  0.48879121  0.17662205\n",
      "  0.17410342 -0.07343502 -0.0314651  -0.89846776  0.00653561 -0.27232555\n",
      " -0.12442075  0.39697177 -0.75318727  0.61067658  0.70544004  0.01789988\n",
      "  0.2090388   0.382747   -0.2795817  -0.10453082 -0.9310132  -0.52642474\n",
      "  1.61398954  1.36735898 -0.49235221 -1.01493649 -0.60567591 -0.34195917\n",
      " -3.17508577]\n",
      "accuracy = 0.8477423638778221\n"
     ]
    }
   ],
   "source": [
    "# result\n",
    "y_pred = logic1.predict(x_test)\n",
    "print(f'w = {logic1.w}')\n",
    "print(f'accuracy = {acc(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case 3: lambda = 1 for numerical-valued features, lambda = 0.5 for binary-valued features, no regularization for intercept term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0: 11771.483285222645\n",
      "iteration 1: 10284.737094728252\n",
      "iteration 2: 9839.022516791465\n",
      "iteration 3: 9768.214608646455\n",
      "iteration 4: 9764.261556174839\n",
      "iteration 5: 9764.222600733669\n",
      "iteration 6: 9764.222592337468\n"
     ]
    }
   ],
   "source": [
    "# compute lambda\n",
    "cols = adult50kp['columnname']\n",
    "num_col = adult50kp['num_col']\n",
    "is_num = np.isin(cols, num_col)\n",
    "lambda_vec = np.array(list(map(lambda b: 1 if b else 0.5, is_num)))\n",
    "lambda_vec = np.append(lambda_vec, 0)\n",
    "\n",
    "# fit\n",
    "logic1 = mylogistic_l2(reg_vec=lambda_vec, max_iter=1000, tol=1e-5, add_intercept=True)\n",
    "logic1.fit(x_train, y_train, verbal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w = [ 0.25851661  0.3533387   2.33562764  0.7825921   0.33439916  0.07940036\n",
      " -0.08347988  0.23309134 -0.59278098 -0.9224849   0.11139573  1.25425869\n",
      " -0.38299462  0.41291781  0.04136013 -0.26411462  0.19283128 -0.42890321\n",
      "  0.42890321  0.23635122  0.30021361  1.03810521 -0.75216086 -0.4534137\n",
      " -0.02691157 -0.5825269  -2.00075382  0.75127891  0.82696617  0.52830705\n",
      "  0.89488994  0.14510375  0.18253094 -0.02583999  0.00991404  0.89862004\n",
      "  0.68517002  0.23294385  0.24519931 -0.38363083 -0.08029608 -0.06493444\n",
      "  0.0453608   0.03743376 -0.01295908 -2.09374319  0.25763304  0.06659781\n",
      "  1.18748312  0.55059265 -0.47576613 -1.45842154  0.5822242  -1.0627833\n",
      " -0.00957211 -0.31704572  0.52485137  0.73044517  0.67457228 -0.63624179\n",
      " -0.00967268  0.17339113 -0.2364757   0.0375474   0.10120874 -0.24679341\n",
      "  0.23800627  0.64228457  1.00567032  0.23258941  0.42267607 -0.35336167\n",
      " -0.29178766 -0.38125401 -0.96291964 -0.45007954  0.512985    0.22019382\n",
      "  0.22640627 -0.04989103 -0.01836864 -0.95953334  0.01656804 -0.32741555\n",
      " -0.14011404  0.42856024 -0.84476926  0.75121645  0.76670733  0.07638783\n",
      "  0.26824615  0.44314098 -0.2205815  -0.04631789 -1.28758289 -0.57187068\n",
      "  1.82502287  1.39622511 -0.54691696 -1.05894077 -0.65551468 -0.38800489\n",
      " -3.36269033]\n",
      "accuracy = 0.847675962815405\n"
     ]
    }
   ],
   "source": [
    "# result\n",
    "y_pred = logic1.predict(x_test)\n",
    "print(f'w = {logic1.w}')\n",
    "print(f'accuracy = {acc(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q3.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the training data into subtraining (90%) and tuning (10%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_subtrain shape: (27145, 102)\n",
      "y_subtrain shape: (27145,)\n",
      "x_tune shape: (3017, 102)\n",
      "y_tune shape: (3017,)\n"
     ]
    }
   ],
   "source": [
    "train = np.concatenate((x_train, np.reshape(y_train, (-1, 1))), axis=1)\n",
    "np.random.shuffle(train)\n",
    "n_subtrain = int(train.shape[0] * 0.9)\n",
    "subtrain = train[:n_subtrain, :]\n",
    "tune = train[n_subtrain:, :]\n",
    "\n",
    "x_subtrain = subtrain[:, :-1]\n",
    "y_subtrain = subtrain[:, -1]\n",
    "x_tune = tune[:, :-1]\n",
    "y_tune = tune[:, -1]\n",
    "print(f'x_subtrain shape: {x_subtrain.shape}')\n",
    "print(f'y_subtrain shape: {y_subtrain.shape}')\n",
    "print(f'x_tune shape: {x_tune.shape}')\n",
    "print(f'y_tune shape: {y_tune.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) Choose a set of grids among a reasonable range. For example, 10 grids in [0.01, 100]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = [0.01, 0.05, 0.1, 0.5, 1, 5, 10, 20, 50, 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) Conduct grid search with the constraint that $a_1 = a_2$. Record the best value $a_1^*$ and $a_2^*$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda = 0.01, accuracy = 0.8468677494199536\n",
      "lambda = 0.05, accuracy = 0.8471992045077892\n",
      "lambda = 0.1, accuracy = 0.8468677494199536\n",
      "lambda = 0.5, accuracy = 0.8475306595956248\n",
      "lambda = 1, accuracy = 0.8478621146834604\n",
      "lambda = 5, accuracy = 0.8468677494199536\n",
      "lambda = 10, accuracy = 0.8455419290686113\n",
      "lambda = 20, accuracy = 0.8445475638051044\n",
      "lambda = 50, accuracy = 0.84487901889294\n",
      "lambda = 100, accuracy = 0.8418959231024197\n"
     ]
    }
   ],
   "source": [
    "a1_op, a2_op = None, None\n",
    "best_acc = 0\n",
    "for lam in grid:\n",
    "    lambda_vec = np.ones(x_subtrain.shape[1]) * lam\n",
    "    lambda_vec = np.append(lambda_vec, 0)\n",
    "    logic1 = mylogistic_l2(reg_vec=lambda_vec, max_iter=1000, tol=1e-5, add_intercept=True)\n",
    "    logic1.fit(x_subtrain, y_subtrain)\n",
    "    pred = logic1.predict(x_tune)\n",
    "    accuracy = acc(y_tune, pred)\n",
    "    print(f'lambda = {lam}, accuracy = {accuracy}')\n",
    "    if accuracy > best_acc:\n",
    "        a1_op = lam\n",
    "        a2_op = lam\n",
    "        best_acc = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best lambda: 1\n"
     ]
    }
   ],
   "source": [
    "assert(a1_op == a2_op)\n",
    "print(f'best lambda: {a1_op}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$a_1^* = a_2^* = 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) Fix $a_1 = a_1^*$ and search $a_2$ for the best value. Call the result the new $a_2^*$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a2 = 0.01, accuracy = 0.8468677494199536\n",
      "a2 = 0.05, accuracy = 0.8471992045077892\n",
      "a2 = 0.1, accuracy = 0.8468677494199536\n",
      "a2 = 0.5, accuracy = 0.8475306595956248\n",
      "a2 = 1, accuracy = 0.8478621146834604\n",
      "a2 = 5, accuracy = 0.8468677494199536\n",
      "a2 = 10, accuracy = 0.8478621146834604\n",
      "a2 = 20, accuracy = 0.8462048392442824\n",
      "a2 = 50, accuracy = 0.8435531985415976\n",
      "a2 = 100, accuracy = 0.8435531985415976\n",
      "best a2: 1\n"
     ]
    }
   ],
   "source": [
    "a2_op = None\n",
    "best_acc = 0\n",
    "for a2 in grid:\n",
    "    cols = adult50kp['columnname']\n",
    "    num_col = adult50kp['num_col']\n",
    "    is_num = np.isin(cols, num_col)\n",
    "    lambda_vec = np.array(list(map(lambda b: a1_op if b else a2, is_num)))\n",
    "    lambda_vec = np.append(lambda_vec, 0)\n",
    "    \n",
    "    logic1 = mylogistic_l2(reg_vec=lambda_vec, max_iter=1000, tol=1e-5, add_intercept=True)\n",
    "    logic1.fit(x_subtrain, y_subtrain)\n",
    "    pred = logic1.predict(x_tune)\n",
    "    accuracy = acc(y_tune, pred)\n",
    "    print(f'a2 = {a2}, accuracy = {accuracy}')\n",
    "    if accuracy > best_acc:\n",
    "        a2_op = a2\n",
    "        best_acc = accuracy\n",
    "print(f'best a2: {a2_op}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$a_2^* = 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(4) Fix $a_2 = a_2^*$ and search $a_1$ for the best value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a1 = 0.01, accuracy = 0.8478621146834604\n",
      "a1 = 0.05, accuracy = 0.8478621146834604\n",
      "a1 = 0.1, accuracy = 0.8478621146834604\n",
      "a1 = 0.5, accuracy = 0.8478621146834604\n",
      "a1 = 1, accuracy = 0.8478621146834604\n",
      "a1 = 5, accuracy = 0.8475306595956248\n",
      "a1 = 10, accuracy = 0.8468677494199536\n",
      "a1 = 20, accuracy = 0.846536294332118\n",
      "a1 = 50, accuracy = 0.8468677494199536\n",
      "a1 = 100, accuracy = 0.8468677494199536\n",
      "best a1: 0.01\n"
     ]
    }
   ],
   "source": [
    "a1_op = None\n",
    "best_acc = 0\n",
    "for a1 in grid:\n",
    "    cols = adult50kp['columnname']\n",
    "    num_col = adult50kp['num_col']\n",
    "    is_num = np.isin(cols, num_col)\n",
    "    lambda_vec = np.array(list(map(lambda b: a1 if b else a2_op, is_num)))\n",
    "    lambda_vec = np.append(lambda_vec, 0)\n",
    "    \n",
    "    logic1 = mylogistic_l2(reg_vec=lambda_vec, max_iter=1000, tol=1e-5, add_intercept=True)\n",
    "    logic1.fit(x_subtrain, y_subtrain)\n",
    "    pred = logic1.predict(x_tune)\n",
    "    accuracy = acc(y_tune, pred)\n",
    "    print(f'a1 = {a1}, accuracy = {accuracy}')\n",
    "    if accuracy > best_acc:\n",
    "        a1_op = a1\n",
    "        best_acc = accuracy\n",
    "print(f'best a1: {a1_op}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$a_1^* = 0.01$\n",
    "selected lambda: $(a_1^*, a_2^*) = (0.01, 1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(4) Train a model using the selected hyper-parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0: 11773.440290239803\n",
      "iteration 1: 10287.941779628818\n",
      "iteration 2: 9843.220191724415\n",
      "iteration 3: 9773.621838672123\n",
      "iteration 4: 9770.00190839761\n",
      "iteration 5: 9769.970170068025\n",
      "iteration 6: 9769.970164264001\n",
      "accuracy = 0.847808764940239\n"
     ]
    }
   ],
   "source": [
    "# compute lambda\n",
    "a1_op, a2_op = 0.01, 1\n",
    "cols = adult50kp['columnname']\n",
    "num_col = adult50kp['num_col']\n",
    "is_num = np.isin(cols, num_col)\n",
    "lambda_vec = np.array(list(map(lambda b: a1_op if b else a2_op, is_num)))\n",
    "lambda_vec = np.append(lambda_vec, 0)\n",
    "\n",
    "# fit\n",
    "logic1 = mylogistic_l2(reg_vec=lambda_vec, max_iter=1000, tol=1e-5, add_intercept=True)\n",
    "logic1.fit(x_train, y_train, verbal=True)\n",
    "\n",
    "# predict\n",
    "pred = logic1.predict(x_test)\n",
    "accuracy = acc(y_test, pred)\n",
    "print(f'accuracy = {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q3.4\n",
    "\n",
    "Tune hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_c = 1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# tune hyperparameter\n",
    "grid = [0.01, 0.05, 0.1, 0.5, 1, 5, 10, 20, 50, 100]\n",
    "best_acc = 0\n",
    "best_c = None\n",
    "for c in grid:\n",
    "    clf = LogisticRegression(C=c, fit_intercept=True, max_iter=1000)\n",
    "    clf.fit(x_subtrain, y_subtrain)\n",
    "    pred = clf.predict(x_tune)\n",
    "    accuracy = acc(y_tune, pred)\n",
    "    if accuracy > best_acc:\n",
    "        best_acc = accuracy\n",
    "        best_c = c\n",
    "print(f'best_c = {best_c}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a model with the selected hyperparameter and test on the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.8476095617529881\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(C=best_c, fit_intercept=True, max_iter=1000)\n",
    "clf.fit(x_train, y_train)\n",
    "pred = clf.predict(x_test)\n",
    "accuracy = acc(y_test, pred)\n",
    "print(f'accuracy = {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w = [[ 0.25831095  0.35305992  2.33341248  0.73808509  0.3338047   0.07928801\n",
      "  -0.04665658  0.19446582 -0.58873074 -0.94231022  0.07023909  1.28296743\n",
      "  -0.37711869  0.38795162  0.03709107 -0.26750489  0.18955569 -0.44205094\n",
      "   0.41202574  0.16328127  0.22747833  0.96383541 -0.81876501 -0.52195352\n",
      "  -0.10006898 -0.65087773 -1.55536049  0.67785779  0.74971894  0.45446912\n",
      "   0.8176959   0.07251055  0.07117713 -0.11939837 -0.06421714  0.67143352\n",
      "   0.50205441  0.08666334  0.11242212 -0.38739541 -0.1041518  -0.05391201\n",
      "   0.10474467 -0.02205727  0.01450121 -1.16503835  0.29825238  0.02489636\n",
      "   1.00782193  0.49945656 -0.45755789 -1.24310256  0.52613361 -0.87244122\n",
      "  -0.02884535 -0.31538858  0.47218078  0.62879435  0.62375866 -0.58766648\n",
      "  -0.03065251  0.1240874  -0.14427751  0.02322553  0.0614599  -0.24962885\n",
      "   0.19526249  0.52704901  0.92767816  0.18822848  0.37622549 -0.2896816\n",
      "  -0.31147279 -0.3353401  -0.64187818 -0.38415652  0.48853677  0.17633515\n",
      "   0.1738158  -0.07402117 -0.03277842 -0.89678333  0.00492386 -0.27460353\n",
      "  -0.12581771  0.39608499 -0.75257545  0.61261637  0.69913035  0.01176903\n",
      "   0.20277824  0.37653005 -0.28559652 -0.11062397 -0.92401238 -0.53015683\n",
      "   1.60754365  1.36252655 -0.49580962 -1.01876521 -0.6098672  -0.34549653]]\n",
      "intercept = [-3.13460814]\n"
     ]
    }
   ],
   "source": [
    "print(f'w = {clf.coef_}')\n",
    "print(f'intercept = {clf.intercept_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the accuracy of the *LogisticRegression* model from sklearn are quite close to those obtained from *mylogistic_l2*, with difference around 0.01% only.\n",
    "\n",
    "The weights are similar to those we get in Q3.2 case 1 and case 2. As for Q3.2 case 3, since lambda for binary features decreased, absolute values of the coefficients of binary features appeared to be slightly larger than those in case 2. The coefficients of the *LogisticRegression* model is similar to those in case 2."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
