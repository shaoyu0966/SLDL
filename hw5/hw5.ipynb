{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Learning and Deep Learning HW5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['train', 'valid' ,'test']\n",
    "labels = ['blazer', 'cardigan', 'coat', 'jacket']\n",
    "base_path = '/tmp2/b06705028/sldl'\n",
    "data_path = f'{base_path}/photos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      blazer cardigan coat jacket  total\n",
      "train     97      237  296    411   1041\n",
      "valid      7       36   27     35    105\n",
      "test       9       42   43     52    146\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=labels, index=datasets)\n",
    "for ds in datasets:\n",
    "    for lb in labels:\n",
    "        basepath = os.path.join(f'{data_path}/{ds}/{lb}/', '*.jpg')\n",
    "        cand_fn = glob.glob(basepath)\n",
    "        df[lb][ds] = len(cand_fn)\n",
    "df['total'] = df.sum(axis=1).astype('int')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio:\n",
      "         blazer  cardigan      coat    jacket\n",
      "train  0.093180  0.227666  0.284342  0.394813\n",
      "valid  0.066667  0.342857  0.257143  0.333333\n",
      "test   0.061644  0.287671  0.294521  0.356164\n"
     ]
    }
   ],
   "source": [
    "print('Ratio:')\n",
    "df = df.drop(['total'], axis=1)\n",
    "print (df.div(df.sum(axis=1), axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the number of instances of each image type, I suggest that the accuracy of the classification task will be jacket > coat > cardigan > blazer. This follows the hypothesis that larger number of instances in training set causes higher classification accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image transformations\n",
    "image_transforms = {\n",
    "    'train':\n",
    "        transforms.Compose([\n",
    "        transforms.Resize(size=256),\n",
    "        transforms.RandomResizedCrop(size=(224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(degrees=20),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    \n",
    "    'valid':\n",
    "        transforms.Compose([\n",
    "        transforms.Resize(size=256),\n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        # transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    \n",
    "    'test':\n",
    "        transforms.Compose([\n",
    "        transforms.Resize(size=256),\n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        # transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets from folders\n",
    "data = {\n",
    "    'train': ImageFolder(root=f'{data_path}/train/', transform=image_transforms['train']),\n",
    "    'valid': ImageFolder(root=f'{data_path}/valid/', transform=image_transforms['valid']),\n",
    "    'test': ImageFolder(root=f'{data_path}/test/', transform=image_transforms['test'])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader\n",
    "batch_size = 32\n",
    "dataloaders = {\n",
    "    'train': DataLoader(data['train'], batch_size=batch_size, shuffle=True, num_workers=4),\n",
    "    'valid': DataLoader(data['valid'], batch_size=batch_size, shuffle=True, num_workers=4),\n",
    "    'test': DataLoader(data['test'], batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda 0\n"
     ]
    }
   ],
   "source": [
    "# device\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'using {device} {torch.cuda.current_device()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss(model, data_loader):\n",
    "    loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch, (inputs, targets) in enumerate(data_loader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss += loss_fn(outputs, targets)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(optim, model, weight_path, early_stop_patient=20, max_epoch=200):\n",
    "    best_valid_loss = np.inf\n",
    "    best_valid_epoch = 0\n",
    "    for epoch in range(max_epoch):\n",
    "        # train\n",
    "        train_loss = 0\n",
    "        for batch, (inputs, targets) in enumerate(dataloaders['train']):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            model.train()\n",
    "            optim.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "        # validation\n",
    "        model.eval()\n",
    "        valid_loss = cross_entropy_loss(model, dataloaders['valid']).cpu().numpy()\n",
    " \n",
    "        # update weight if lower validation loss\n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            best_valid_epoch = epoch\n",
    "            torch.save(model, weight_path)\n",
    "            \n",
    "        # early stopping\n",
    "        elif (epoch - best_valid_epoch >= early_stop_patient):\n",
    "            print(f'early stopping at epoch {epoch}, best_valid = {best_valid_loss:.3f}')\n",
    "            return best_valid_loss\n",
    "        \n",
    "        if (epoch % 20 == 0):\n",
    "            print(f'epoch {epoch}: train_loss = {train_loss:.3f}, valid_loss = {valid_loss:.3f}, best_valid = {best_valid_loss:.3f}')\n",
    "    \n",
    "    return best_valid_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================\n",
      "train SGD lr = 0.001, weight_decay = 0\n",
      "model at cuda\n",
      "epoch 0: train_loss = 42.875, valid_loss = 5.238, best_valid = 5.238\n",
      "epoch 20: train_loss = 34.223, valid_loss = 4.460, best_valid = 4.294\n",
      "epoch 40: train_loss = 27.082, valid_loss = 3.820, best_valid = 3.635\n",
      "epoch 60: train_loss = 22.329, valid_loss = 3.515, best_valid = 3.164\n",
      "epoch 80: train_loss = 18.321, valid_loss = 3.115, best_valid = 3.115\n",
      "epoch 100: train_loss = 15.469, valid_loss = 2.882, best_valid = 2.849\n",
      "early stopping at epoch 111, best_valid = 2.849\n",
      "\n",
      "============================================\n",
      "train SGD lr = 0.001, weight_decay = 0.0001\n",
      "model at cuda\n",
      "epoch 0: train_loss = 42.475, valid_loss = 5.346, best_valid = 5.346\n",
      "epoch 20: train_loss = 34.183, valid_loss = 4.603, best_valid = 4.307\n",
      "epoch 40: train_loss = 25.705, valid_loss = 3.771, best_valid = 3.586\n",
      "epoch 60: train_loss = 21.222, valid_loss = 3.642, best_valid = 3.178\n",
      "epoch 80: train_loss = 18.036, valid_loss = 3.146, best_valid = 3.073\n",
      "epoch 100: train_loss = 13.140, valid_loss = 3.039, best_valid = 2.708\n",
      "early stopping at epoch 119, best_valid = 2.708\n",
      "\n",
      "============================================\n",
      "train SGD lr = 0.001, weight_decay = 0.001\n",
      "model at cuda\n",
      "epoch 0: train_loss = 43.379, valid_loss = 5.135, best_valid = 5.135\n",
      "epoch 20: train_loss = 33.857, valid_loss = 4.443, best_valid = 4.273\n",
      "epoch 40: train_loss = 27.754, valid_loss = 3.562, best_valid = 3.562\n",
      "epoch 60: train_loss = 21.626, valid_loss = 3.364, best_valid = 3.293\n",
      "epoch 80: train_loss = 18.577, valid_loss = 3.265, best_valid = 3.028\n",
      "epoch 100: train_loss = 14.909, valid_loss = 3.204, best_valid = 2.843\n",
      "early stopping at epoch 108, best_valid = 2.843\n",
      "\n",
      "============================================\n",
      "train SGD lr = 0.005, weight_decay = 0\n",
      "model at cuda\n",
      "epoch 0: train_loss = 42.566, valid_loss = 5.113, best_valid = 5.113\n",
      "epoch 20: train_loss = 17.295, valid_loss = 3.504, best_valid = 3.014\n",
      "early stopping at epoch 39, best_valid = 3.014\n",
      "\n",
      "============================================\n",
      "train SGD lr = 0.005, weight_decay = 0.0001\n",
      "model at cuda\n",
      "epoch 0: train_loss = 42.214, valid_loss = 4.984, best_valid = 4.984\n",
      "epoch 20: train_loss = 16.232, valid_loss = 3.130, best_valid = 2.774\n",
      "early stopping at epoch 39, best_valid = 2.774\n",
      "\n",
      "============================================\n",
      "train SGD lr = 0.005, weight_decay = 0.001\n",
      "model at cuda\n",
      "epoch 0: train_loss = 42.170, valid_loss = 4.829, best_valid = 4.829\n",
      "epoch 20: train_loss = 16.573, valid_loss = 2.936, best_valid = 2.936\n",
      "epoch 40: train_loss = 7.676, valid_loss = 3.237, best_valid = 2.872\n",
      "early stopping at epoch 46, best_valid = 2.872\n",
      "\n",
      "============================================\n",
      "train SGD lr = 0.01, weight_decay = 0\n",
      "model at cuda\n",
      "epoch 0: train_loss = 42.236, valid_loss = 5.135, best_valid = 5.135\n",
      "epoch 20: train_loss = 11.525, valid_loss = 7.026, best_valid = 3.345\n",
      "early stopping at epoch 26, best_valid = 3.345\n",
      "\n",
      "============================================\n",
      "train SGD lr = 0.01, weight_decay = 0.0001\n",
      "model at cuda\n",
      "epoch 0: train_loss = 43.018, valid_loss = 4.700, best_valid = 4.700\n",
      "epoch 20: train_loss = 9.961, valid_loss = 3.697, best_valid = 3.195\n",
      "early stopping at epoch 38, best_valid = 3.195\n",
      "\n",
      "============================================\n",
      "train SGD lr = 0.01, weight_decay = 0.001\n",
      "model at cuda\n",
      "epoch 0: train_loss = 44.087, valid_loss = 4.849, best_valid = 4.849\n",
      "epoch 20: train_loss = 10.473, valid_loss = 4.871, best_valid = 3.144\n",
      "early stopping at epoch 29, best_valid = 3.144\n",
      "\n",
      "============================================\n",
      "train SGD lr = 0.05, weight_decay = 0\n",
      "model at cuda\n",
      "epoch 0: train_loss = 77.870, valid_loss = 5.138, best_valid = 5.138\n",
      "epoch 20: train_loss = 14.877, valid_loss = 4.761, best_valid = 3.202\n",
      "early stopping at epoch 37, best_valid = 3.202\n",
      "\n",
      "============================================\n",
      "train SGD lr = 0.05, weight_decay = 0.0001\n",
      "model at cuda\n",
      "epoch 0: train_loss = 78.118, valid_loss = 5.230, best_valid = 5.230\n",
      "epoch 20: train_loss = 14.427, valid_loss = 4.698, best_valid = 3.717\n",
      "early stopping at epoch 32, best_valid = 3.717\n",
      "\n",
      "============================================\n",
      "train SGD lr = 0.05, weight_decay = 0.001\n",
      "model at cuda\n",
      "epoch 0: train_loss = 74.059, valid_loss = 4.931, best_valid = 4.931\n",
      "epoch 20: train_loss = 13.495, valid_loss = 4.835, best_valid = 3.616\n",
      "epoch 40: train_loss = 7.388, valid_loss = 5.906, best_valid = 3.496\n",
      "early stopping at epoch 41, best_valid = 3.496\n"
     ]
    }
   ],
   "source": [
    "all_lr = [0.001, 0.005, 0.01, 0.05]\n",
    "all_wd = [0, 0.0001, 0.001]\n",
    "sgd_valid = pd.DataFrame(columns=all_lr, index=all_wd)\n",
    "\n",
    "for lr in all_lr:\n",
    "    for wd in all_wd:\n",
    "        print('\\n============================================')\n",
    "        print(f'train SGD lr = {lr}, weight_decay = {wd}')\n",
    "        weight_path = f'{base_path}/Q2_weight_{lr}_{wd}'\n",
    "\n",
    "        # load pretrained resnet50 and set the output dimension to 4\n",
    "        model = models.resnet50(pretrained=True)\n",
    "        model.fc = nn.Linear(model.fc.in_features, 4)\n",
    "        model.to(device)\n",
    "        print(f'model at {device}')\n",
    "\n",
    "        # train\n",
    "        optim = torch.optim.SGD(model.parameters(), lr=lr, weight_decay=wd)\n",
    "        valid_loss = train(optim, model, weight_path)\n",
    "        sgd_valid[lr][wd] = valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0.001      0.005      0.010      0.050\n",
      "0.0000  2.8494473  3.0142472  3.3445148  3.2017083\n",
      "0.0001  2.7076368  2.7738614  3.1947072  3.7165773\n",
      "0.0010  2.8433902  2.8717287  3.1435347  3.4962337\n",
      "(x_axis: learning rate)\n",
      "(y_axis: weight decay)\n",
      "\n",
      "minimum validation loss 2.708 at lr=0.001, wd=0.0001\n"
     ]
    }
   ],
   "source": [
    "print(sgd_valid)\n",
    "print('(x_axis: learning rate)')\n",
    "print('(y_axis: weight decay)\\n')\n",
    "\n",
    "sgd_min_wd = -1\n",
    "sgd_min_lr = -1\n",
    "sgd_minimum = np.inf\n",
    "for lr in sgd_valid.columns:\n",
    "    for wd in sgd_valid.index:\n",
    "        if sgd_valid[lr][wd] < sgd_minimum:\n",
    "            sgd_min_wd = wd\n",
    "            sgd_min_lr = lr\n",
    "            sgd_minimum = sgd_valid[lr][wd]\n",
    "print(f'minimum validation loss {sgd_minimum:.3f} at lr={sgd_min_lr}, wd={sgd_min_wd}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load /tmp2/b06705028/sldl/Q2_weight_0.001_0.0001\n",
      "(SGD) test accuracy: 0.6917808219178082\n"
     ]
    }
   ],
   "source": [
    "weight_path = f'{base_path}/Q2_weight_{sgd_min_lr}_{sgd_min_wd}'\n",
    "print(f'load {weight_path}')\n",
    "saved_model = torch.load(weight_path)\n",
    "test_size = len(data['test'])\n",
    "n_correct = 0\n",
    "with torch.no_grad():\n",
    "    for batch, (inputs, targets) in enumerate(dataloaders['test']):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = saved_model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct = (targets==preds).cpu().numpy()\n",
    "        n_correct += np.sum(correct)\n",
    "print(f'(SGD) test accuracy: {n_correct / test_size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================\n",
      "train Adam lr = 1e-05, weight decay = 0\n",
      "model at cuda\n",
      "epoch 0: train_loss = 45.607, valid_loss = 5.620, best_valid = 5.620\n",
      "epoch 20: train_loss = 14.713, valid_loss = 3.586, best_valid = 3.244\n",
      "epoch 40: train_loss = 8.418, valid_loss = 3.512, best_valid = 2.990\n",
      "early stopping at epoch 47, best_valid = 2.990\n",
      "\n",
      "============================================\n",
      "train Adam lr = 1e-05, weight decay = 0.0001\n",
      "model at cuda\n",
      "epoch 0: train_loss = 47.093, valid_loss = 5.556, best_valid = 5.556\n",
      "epoch 20: train_loss = 14.889, valid_loss = 3.537, best_valid = 2.983\n",
      "early stopping at epoch 37, best_valid = 2.983\n",
      "\n",
      "============================================\n",
      "train Adam lr = 1e-05, weight decay = 0.001\n",
      "model at cuda\n",
      "epoch 0: train_loss = 46.690, valid_loss = 5.218, best_valid = 5.218\n",
      "epoch 20: train_loss = 14.846, valid_loss = 3.726, best_valid = 3.332\n",
      "epoch 40: train_loss = 7.889, valid_loss = 4.375, best_valid = 3.192\n",
      "early stopping at epoch 47, best_valid = 3.192\n",
      "\n",
      "============================================\n",
      "train Adam lr = 5e-05, weight decay = 0\n",
      "model at cuda\n",
      "epoch 0: train_loss = 39.532, valid_loss = 4.439, best_valid = 4.439\n",
      "epoch 20: train_loss = 7.987, valid_loss = 5.074, best_valid = 3.041\n",
      "early stopping at epoch 29, best_valid = 3.041\n",
      "\n",
      "============================================\n",
      "train Adam lr = 5e-05, weight decay = 0.0001\n",
      "model at cuda\n",
      "epoch 0: train_loss = 40.151, valid_loss = 5.074, best_valid = 5.074\n",
      "epoch 20: train_loss = 7.198, valid_loss = 3.967, best_valid = 2.877\n",
      "early stopping at epoch 31, best_valid = 2.877\n",
      "\n",
      "============================================\n",
      "train Adam lr = 5e-05, weight decay = 0.001\n",
      "model at cuda\n",
      "epoch 0: train_loss = 39.704, valid_loss = 4.301, best_valid = 4.301\n",
      "epoch 20: train_loss = 6.569, valid_loss = 3.191, best_valid = 2.662\n",
      "early stopping at epoch 31, best_valid = 2.662\n",
      "\n",
      "============================================\n",
      "train Adam lr = 0.0001, weight decay = 0\n",
      "model at cuda\n",
      "epoch 0: train_loss = 38.180, valid_loss = 4.132, best_valid = 4.132\n",
      "epoch 20: train_loss = 8.584, valid_loss = 3.477, best_valid = 3.136\n",
      "early stopping at epoch 39, best_valid = 3.136\n",
      "\n",
      "============================================\n",
      "train Adam lr = 0.0001, weight decay = 0.0001\n",
      "model at cuda\n",
      "epoch 0: train_loss = 38.757, valid_loss = 4.398, best_valid = 4.398\n",
      "epoch 20: train_loss = 7.913, valid_loss = 5.110, best_valid = 3.087\n",
      "epoch 40: train_loss = 6.514, valid_loss = 4.527, best_valid = 3.062\n",
      "early stopping at epoch 46, best_valid = 3.062\n",
      "\n",
      "============================================\n",
      "train Adam lr = 0.0001, weight decay = 0.001\n",
      "model at cuda\n",
      "epoch 0: train_loss = 38.752, valid_loss = 4.047, best_valid = 4.047\n",
      "epoch 20: train_loss = 8.010, valid_loss = 5.306, best_valid = 2.835\n",
      "early stopping at epoch 27, best_valid = 2.835\n",
      "\n",
      "============================================\n",
      "train Adam lr = 0.0005, weight decay = 0\n",
      "model at cuda\n",
      "epoch 0: train_loss = 44.312, valid_loss = 10.991, best_valid = 10.991\n",
      "epoch 20: train_loss = 23.008, valid_loss = 5.598, best_valid = 3.792\n",
      "epoch 40: train_loss = 15.729, valid_loss = 5.254, best_valid = 3.290\n",
      "early stopping at epoch 46, best_valid = 3.290\n",
      "\n",
      "============================================\n",
      "train Adam lr = 0.0005, weight decay = 0.0001\n",
      "model at cuda\n",
      "epoch 0: train_loss = 43.925, valid_loss = 4.936, best_valid = 4.936\n",
      "epoch 20: train_loss = 21.481, valid_loss = 4.036, best_valid = 3.513\n",
      "early stopping at epoch 34, best_valid = 3.513\n",
      "\n",
      "============================================\n",
      "train Adam lr = 0.0005, weight decay = 0.001\n",
      "model at cuda\n",
      "epoch 0: train_loss = 43.287, valid_loss = 5.297, best_valid = 5.297\n",
      "epoch 20: train_loss = 28.492, valid_loss = 4.506, best_valid = 4.506\n",
      "early stopping at epoch 40, best_valid = 4.506\n"
     ]
    }
   ],
   "source": [
    "all_lr = [0.00001, 0.00005, 0.0001, 0.0005]\n",
    "all_wd = [0, 0.0001, 0.001]\n",
    "adam_valid = pd.DataFrame(columns=all_lr, index=all_wd)\n",
    "\n",
    "for lr in all_lr:\n",
    "    for wd in all_wd:\n",
    "        print('\\n============================================')\n",
    "        print(f'train Adam lr = {lr}, weight decay = {wd}')\n",
    "        weight_path = f'{base_path}/Q2_weight_adam_{lr}_{wd}'\n",
    "\n",
    "        # load pretrained resnet50 and set the output dimension to 4\n",
    "        model = models.resnet50(pretrained=True)\n",
    "        model.fc = nn.Linear(model.fc.in_features, 4)\n",
    "        model.to(device)\n",
    "        print(f'model at {device}')\n",
    "\n",
    "        # train\n",
    "        optim = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "        adam_valid[lr][wd] = train(optim, model, weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0.00001    0.00005    0.00010    0.00050\n",
      "0.0000    2.99024   3.041418  3.1356177  3.2901216\n",
      "0.0001  2.9833064  2.8774087  3.0620637  3.5125751\n",
      "0.0010  3.1924808   2.661787  2.8352168  4.5057206\n",
      "(x_axis: learning rate)\n",
      "(y_axis: weight decay)\n",
      "\n",
      "minimum validation loss 2.662 at lr=5e-05, wd=0.001\n"
     ]
    }
   ],
   "source": [
    "print(adam_valid)\n",
    "print('(x_axis: learning rate)')\n",
    "print('(y_axis: weight decay)\\n')\n",
    "\n",
    "adam_min_wd = -1\n",
    "adam_min_lr = -1\n",
    "adam_minimum = np.inf\n",
    "for lr in adam_valid.columns:\n",
    "    for wd in adam_valid.index:\n",
    "        if adam_valid[lr][wd] < adam_minimum:\n",
    "            adam_min_wd = wd\n",
    "            adam_min_lr = lr\n",
    "            adam_minimum = adam_valid[lr][wd]\n",
    "print(f'minimum validation loss {adam_minimum:.3f} at lr={adam_min_lr}, wd={adam_min_wd}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load /tmp2/b06705028/sldl/Q2_weight_adam_5e-05_0.001\n",
      "(Adam) test accuracy: 0.6917808219178082\n"
     ]
    }
   ],
   "source": [
    "weight_path = f'{base_path}/Q2_weight_adam_{adam_min_lr}_{adam_min_wd}'\n",
    "print(f'load {weight_path}')\n",
    "saved_model = torch.load(weight_path)\n",
    "test_size = len(data['test'])\n",
    "n_correct = 0\n",
    "with torch.no_grad():\n",
    "    for batch, (inputs, targets) in enumerate(dataloaders['test']):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = saved_model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct = (targets==preds).cpu().numpy()\n",
    "        n_correct += np.sum(correct)\n",
    "print(f'(Adam) test accuracy: {n_correct / test_size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test accuracy: 0.692"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (row: truth, column: predicted)\n",
      "\n",
      "[[ 5  0  2  2]\n",
      " [ 2 21 10  9]\n",
      " [ 0  5 33  5]\n",
      " [ 2  7  1 42]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "confusion = np.zeros((len(labels), len(labels)))\n",
    "weight_path = '/tmp2/b06705028/sldl/Q2_weight_adam_5e-05_0.001'\n",
    "saved_model = torch.load(weight_path)\n",
    "y_truth = np.array([])\n",
    "y_pred = np.array([])\n",
    "with torch.no_grad():\n",
    "    for batch, (inputs, targets) in enumerate(dataloaders['test']):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = saved_model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        y_truth = np.concatenate((y_truth, targets.cpu().numpy()))\n",
    "        y_pred = np.concatenate((y_pred, preds.cpu().numpy()))\n",
    "confusion = confusion_matrix(y_truth, y_pred)\n",
    "print('Confusion Matrix (row: truth, column: predicted)\\n')\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blazer: 0.556\n",
      "cardigan: 0.500\n",
      "coat: 0.767\n",
      "jacket: 0.808\n"
     ]
    }
   ],
   "source": [
    "# per class accuracy\n",
    "for i in range(len(labels)):\n",
    "    total = confusion[i].sum()\n",
    "    correct = confusion[i][i]\n",
    "    print(f'{labels[i]}: {correct / total:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Q1, we guessed that per-class accuracy will be jacket > coat > cardigan > blazer. Actually, the relation between them is jacket > coat> blazer > cardigan . Prediction accuracy of blazer is higher that of cardigan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3\n",
    "\n",
    "#### SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================\n",
      "train SGD lr = 0.001, weight_decay = 0\n",
      "model at cuda\n",
      "epoch 0: train_loss = 43.137, valid_loss = 5.371, best_valid = 5.371\n",
      "epoch 20: train_loss = 38.277, valid_loss = 4.632, best_valid = 4.632\n",
      "epoch 40: train_loss = 36.090, valid_loss = 4.440, best_valid = 4.384\n",
      "epoch 60: train_loss = 35.226, valid_loss = 4.436, best_valid = 4.301\n",
      "early stopping at epoch 75, best_valid = 4.301\n",
      "\n",
      "============================================\n",
      "train SGD lr = 0.001, weight_decay = 0.0001\n",
      "model at cuda\n",
      "epoch 0: train_loss = 43.646, valid_loss = 5.295, best_valid = 5.295\n",
      "epoch 20: train_loss = 37.954, valid_loss = 4.658, best_valid = 4.629\n",
      "epoch 40: train_loss = 36.527, valid_loss = 4.697, best_valid = 4.408\n",
      "epoch 60: train_loss = 34.944, valid_loss = 4.391, best_valid = 4.293\n",
      "epoch 80: train_loss = 34.460, valid_loss = 4.613, best_valid = 4.277\n",
      "epoch 100: train_loss = 34.304, valid_loss = 4.243, best_valid = 4.188\n",
      "early stopping at epoch 111, best_valid = 4.188\n",
      "\n",
      "============================================\n",
      "train SGD lr = 0.001, weight_decay = 0.001\n",
      "model at cuda\n",
      "epoch 0: train_loss = 42.955, valid_loss = 5.118, best_valid = 5.118\n",
      "epoch 20: train_loss = 38.362, valid_loss = 4.729, best_valid = 4.644\n",
      "epoch 40: train_loss = 36.716, valid_loss = 4.476, best_valid = 4.343\n",
      "epoch 60: train_loss = 35.001, valid_loss = 4.359, best_valid = 4.326\n",
      "epoch 80: train_loss = 34.445, valid_loss = 4.359, best_valid = 4.232\n",
      "early stopping at epoch 99, best_valid = 4.232\n",
      "\n",
      "============================================\n",
      "train SGD lr = 0.005, weight_decay = 0\n",
      "model at cuda\n",
      "epoch 0: train_loss = 42.870, valid_loss = 5.382, best_valid = 5.382\n",
      "epoch 20: train_loss = 34.302, valid_loss = 4.532, best_valid = 4.382\n",
      "epoch 40: train_loss = 32.567, valid_loss = 4.616, best_valid = 4.210\n",
      "early stopping at epoch 44, best_valid = 4.210\n",
      "\n",
      "============================================\n",
      "train SGD lr = 0.005, weight_decay = 0.0001\n",
      "model at cuda\n",
      "epoch 0: train_loss = 42.925, valid_loss = 4.903, best_valid = 4.903\n",
      "epoch 20: train_loss = 34.258, valid_loss = 4.478, best_valid = 4.428\n",
      "epoch 40: train_loss = 32.614, valid_loss = 4.415, best_valid = 4.267\n",
      "early stopping at epoch 58, best_valid = 4.267\n",
      "\n",
      "============================================\n",
      "train SGD lr = 0.005, weight_decay = 0.001\n",
      "model at cuda\n",
      "epoch 0: train_loss = 42.261, valid_loss = 5.308, best_valid = 5.308\n",
      "epoch 20: train_loss = 33.588, valid_loss = 4.531, best_valid = 4.281\n",
      "epoch 40: train_loss = 31.719, valid_loss = 4.485, best_valid = 4.243\n",
      "early stopping at epoch 51, best_valid = 4.243\n",
      "\n",
      "============================================\n",
      "train SGD lr = 0.01, weight_decay = 0\n",
      "model at cuda\n",
      "epoch 0: train_loss = 43.833, valid_loss = 5.147, best_valid = 5.147\n",
      "epoch 20: train_loss = 32.833, valid_loss = 4.982, best_valid = 4.368\n",
      "epoch 40: train_loss = 33.955, valid_loss = 4.720, best_valid = 4.300\n",
      "early stopping at epoch 53, best_valid = 4.300\n",
      "\n",
      "============================================\n",
      "train SGD lr = 0.01, weight_decay = 0.0001\n",
      "model at cuda\n",
      "epoch 0: train_loss = 43.266, valid_loss = 4.809, best_valid = 4.809\n",
      "epoch 20: train_loss = 33.789, valid_loss = 5.033, best_valid = 4.348\n",
      "early stopping at epoch 24, best_valid = 4.348\n",
      "\n",
      "============================================\n",
      "train SGD lr = 0.01, weight_decay = 0.001\n",
      "model at cuda\n",
      "epoch 0: train_loss = 43.413, valid_loss = 5.309, best_valid = 5.309\n",
      "epoch 20: train_loss = 33.904, valid_loss = 5.021, best_valid = 4.384\n",
      "early stopping at epoch 25, best_valid = 4.384\n",
      "\n",
      "============================================\n",
      "train SGD lr = 0.05, weight_decay = 0\n",
      "model at cuda\n",
      "epoch 0: train_loss = 191.178, valid_loss = 7.566, best_valid = 7.566\n",
      "epoch 20: train_loss = 95.948, valid_loss = 15.719, best_valid = 5.773\n",
      "early stopping at epoch 31, best_valid = 5.773\n",
      "\n",
      "============================================\n",
      "train SGD lr = 0.05, weight_decay = 0.0001\n",
      "model at cuda\n",
      "epoch 0: train_loss = 199.982, valid_loss = 34.638, best_valid = 34.638\n",
      "epoch 20: train_loss = 106.003, valid_loss = 14.285, best_valid = 6.597\n",
      "early stopping at epoch 34, best_valid = 6.597\n",
      "\n",
      "============================================\n",
      "train SGD lr = 0.05, weight_decay = 0.001\n",
      "model at cuda\n",
      "epoch 0: train_loss = 219.816, valid_loss = 34.173, best_valid = 34.173\n",
      "epoch 20: train_loss = 90.137, valid_loss = 13.798, best_valid = 6.652\n",
      "early stopping at epoch 37, best_valid = 6.652\n"
     ]
    }
   ],
   "source": [
    "all_lr = [0.001, 0.005, 0.01, 0.05]\n",
    "all_wd = [0, 0.0001, 0.001]\n",
    "sgd_valid = pd.DataFrame(columns=all_lr, index=all_wd)\n",
    "\n",
    "for lr in all_lr:\n",
    "    for wd in all_wd:\n",
    "        print('\\n============================================')\n",
    "        print(f'train SGD lr = {lr}, weight_decay = {wd}')\n",
    "        weight_path = f'{base_path}/Q3_weight_{lr}_{wd}'\n",
    "\n",
    "        # load pretrained resnet50 and set the output dimension to 4\n",
    "        model = models.resnet50(pretrained=True)\n",
    "        model.fc = nn.Linear(model.fc.in_features, 4)\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in model.fc.parameters():\n",
    "            param.requires_grad = True\n",
    "        model.to(device)\n",
    "        print(f'model at {device}')\n",
    "\n",
    "        # train\n",
    "        optim = torch.optim.SGD(model.parameters(), lr=lr, weight_decay=wd)\n",
    "        valid_loss = train(optim, model, weight_path)\n",
    "        sgd_valid[lr][wd] = valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0.001      0.005      0.010      0.050\n",
      "0.0000  4.300536   4.209583   4.299723  5.7730145\n",
      "0.0001  4.188382   4.266525  4.3477793   6.596818\n",
      "0.0010  4.232094  4.2428756   4.383698  6.6515093\n",
      "(x_axis: learning rate)\n",
      "(y_axis: weight decay)\n",
      "\n",
      "minimum validation loss 4.188 at lr=0.001, wd=0.0001\n"
     ]
    }
   ],
   "source": [
    "print(sgd_valid)\n",
    "print('(x_axis: learning rate)')\n",
    "print('(y_axis: weight decay)\\n')\n",
    "\n",
    "sgd_min_wd = -1\n",
    "sgd_min_lr = -1\n",
    "sgd_minimum = np.inf\n",
    "for lr in sgd_valid.columns:\n",
    "    for wd in sgd_valid.index:\n",
    "        if sgd_valid[lr][wd] < sgd_minimum:\n",
    "            sgd_min_wd = wd\n",
    "            sgd_min_lr = lr\n",
    "            sgd_minimum = sgd_valid[lr][wd]\n",
    "print(f'minimum validation loss {sgd_minimum:.3f} at lr={sgd_min_lr}, wd={sgd_min_wd}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(SGD) test accuracy: 0.4931506849315068\n"
     ]
    }
   ],
   "source": [
    "weight_path = f'{base_path}/Q3_weight_{sgd_min_lr}_{sgd_min_wd}'\n",
    "saved_model = torch.load(weight_path)\n",
    "test_size = len(data['test'])\n",
    "n_correct = 0\n",
    "with torch.no_grad():\n",
    "    for batch, (inputs, targets) in enumerate(dataloaders['test']):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = saved_model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct = (targets==preds).cpu().numpy()\n",
    "        n_correct += np.sum(correct)\n",
    "print(f'(SGD) test accuracy: {n_correct / test_size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================\n",
      "train Adam lr = 1e-05, weight decay = 0\n",
      "model at cuda\n",
      "epoch 0: train_loss = 45.747, valid_loss = 5.418, best_valid = 5.418\n",
      "epoch 20: train_loss = 41.365, valid_loss = 5.080, best_valid = 4.998\n",
      "epoch 40: train_loss = 40.284, valid_loss = 4.848, best_valid = 4.848\n",
      "epoch 60: train_loss = 39.538, valid_loss = 4.833, best_valid = 4.775\n",
      "epoch 80: train_loss = 38.684, valid_loss = 4.734, best_valid = 4.671\n",
      "epoch 100: train_loss = 37.721, valid_loss = 4.722, best_valid = 4.480\n",
      "early stopping at epoch 117, best_valid = 4.480\n",
      "\n",
      "============================================\n",
      "train Adam lr = 1e-05, weight decay = 0.0001\n",
      "model at cuda\n",
      "epoch 0: train_loss = 45.011, valid_loss = 5.504, best_valid = 5.504\n",
      "epoch 20: train_loss = 41.518, valid_loss = 5.281, best_valid = 5.055\n",
      "epoch 40: train_loss = 40.125, valid_loss = 5.122, best_valid = 4.971\n",
      "epoch 60: train_loss = 39.277, valid_loss = 5.006, best_valid = 4.885\n",
      "epoch 80: train_loss = 38.431, valid_loss = 5.108, best_valid = 4.809\n",
      "epoch 100: train_loss = 37.765, valid_loss = 5.085, best_valid = 4.693\n",
      "early stopping at epoch 103, best_valid = 4.693\n",
      "\n",
      "============================================\n",
      "train Adam lr = 1e-05, weight decay = 0.001\n",
      "model at cuda\n",
      "epoch 0: train_loss = 49.589, valid_loss = 5.896, best_valid = 5.896\n",
      "epoch 20: train_loss = 41.431, valid_loss = 5.015, best_valid = 4.952\n",
      "epoch 40: train_loss = 40.474, valid_loss = 4.896, best_valid = 4.862\n",
      "epoch 60: train_loss = 39.152, valid_loss = 4.869, best_valid = 4.733\n",
      "epoch 80: train_loss = 38.893, valid_loss = 4.673, best_valid = 4.673\n",
      "epoch 100: train_loss = 38.478, valid_loss = 4.672, best_valid = 4.579\n",
      "early stopping at epoch 103, best_valid = 4.579\n",
      "\n",
      "============================================\n",
      "train Adam lr = 5e-05, weight decay = 0\n",
      "model at cuda\n",
      "epoch 0: train_loss = 43.771, valid_loss = 5.492, best_valid = 5.492\n",
      "epoch 20: train_loss = 38.182, valid_loss = 4.712, best_valid = 4.698\n",
      "epoch 40: train_loss = 35.798, valid_loss = 4.555, best_valid = 4.550\n",
      "epoch 60: train_loss = 34.319, valid_loss = 4.543, best_valid = 4.224\n",
      "early stopping at epoch 70, best_valid = 4.224\n",
      "\n",
      "============================================\n",
      "train Adam lr = 5e-05, weight decay = 0.0001\n",
      "model at cuda\n",
      "epoch 0: train_loss = 44.148, valid_loss = 5.319, best_valid = 5.319\n",
      "epoch 20: train_loss = 37.814, valid_loss = 4.768, best_valid = 4.496\n",
      "epoch 40: train_loss = 36.033, valid_loss = 4.676, best_valid = 4.443\n",
      "epoch 60: train_loss = 34.378, valid_loss = 4.510, best_valid = 4.404\n",
      "early stopping at epoch 68, best_valid = 4.404\n",
      "\n",
      "============================================\n",
      "train Adam lr = 5e-05, weight decay = 0.001\n",
      "model at cuda\n",
      "epoch 0: train_loss = 43.091, valid_loss = 5.129, best_valid = 5.129\n",
      "epoch 20: train_loss = 38.022, valid_loss = 4.670, best_valid = 4.670\n",
      "epoch 40: train_loss = 35.916, valid_loss = 4.510, best_valid = 4.422\n",
      "epoch 60: train_loss = 34.755, valid_loss = 4.510, best_valid = 4.289\n",
      "early stopping at epoch 66, best_valid = 4.289\n",
      "\n",
      "============================================\n",
      "train Adam lr = 0.0001, weight decay = 0\n",
      "model at cuda\n",
      "epoch 0: train_loss = 43.280, valid_loss = 4.994, best_valid = 4.994\n",
      "epoch 20: train_loss = 36.040, valid_loss = 4.437, best_valid = 4.437\n",
      "epoch 40: train_loss = 34.068, valid_loss = 4.435, best_valid = 4.290\n",
      "epoch 60: train_loss = 33.253, valid_loss = 4.293, best_valid = 4.243\n",
      "early stopping at epoch 61, best_valid = 4.243\n",
      "\n",
      "============================================\n",
      "train Adam lr = 0.0001, weight decay = 0.0001\n",
      "model at cuda\n",
      "epoch 0: train_loss = 43.094, valid_loss = 5.054, best_valid = 5.054\n",
      "epoch 20: train_loss = 36.045, valid_loss = 4.256, best_valid = 4.256\n",
      "early stopping at epoch 40, best_valid = 4.256\n",
      "\n",
      "============================================\n",
      "train Adam lr = 0.0001, weight decay = 0.001\n",
      "model at cuda\n",
      "epoch 0: train_loss = 43.317, valid_loss = 5.166, best_valid = 5.166\n",
      "epoch 20: train_loss = 35.964, valid_loss = 4.501, best_valid = 4.406\n",
      "epoch 40: train_loss = 33.614, valid_loss = 4.290, best_valid = 4.237\n",
      "epoch 60: train_loss = 32.793, valid_loss = 4.385, best_valid = 4.178\n",
      "early stopping at epoch 67, best_valid = 4.178\n",
      "\n",
      "============================================\n",
      "train Adam lr = 0.0005, weight decay = 0\n",
      "model at cuda\n",
      "epoch 0: train_loss = 43.436, valid_loss = 5.231, best_valid = 5.231\n",
      "epoch 20: train_loss = 32.260, valid_loss = 4.913, best_valid = 4.159\n",
      "early stopping at epoch 27, best_valid = 4.159\n",
      "\n",
      "============================================\n",
      "train Adam lr = 0.0005, weight decay = 0.0001\n",
      "model at cuda\n",
      "epoch 0: train_loss = 42.610, valid_loss = 5.223, best_valid = 5.223\n",
      "epoch 20: train_loss = 33.104, valid_loss = 4.581, best_valid = 4.480\n",
      "epoch 40: train_loss = 31.013, valid_loss = 6.498, best_valid = 4.419\n",
      "early stopping at epoch 49, best_valid = 4.419\n",
      "\n",
      "============================================\n",
      "train Adam lr = 0.0005, weight decay = 0.001\n",
      "model at cuda\n",
      "epoch 0: train_loss = 42.894, valid_loss = 4.827, best_valid = 4.827\n",
      "epoch 20: train_loss = 32.232, valid_loss = 4.797, best_valid = 4.340\n",
      "epoch 40: train_loss = 30.965, valid_loss = 4.354, best_valid = 4.324\n",
      "epoch 60: train_loss = 30.292, valid_loss = 4.923, best_valid = 4.318\n",
      "epoch 80: train_loss = 30.558, valid_loss = 4.487, best_valid = 3.964\n",
      "early stopping at epoch 82, best_valid = 3.964\n"
     ]
    }
   ],
   "source": [
    "all_lr = [0.00001, 0.00005, 0.0001, 0.0005]\n",
    "all_wd = [0, 0.0001, 0.001]\n",
    "adam_valid = pd.DataFrame(columns=all_lr, index=all_wd)\n",
    "\n",
    "for lr in all_lr:\n",
    "    for wd in all_wd:\n",
    "        print('\\n============================================')\n",
    "        print(f'train Adam lr = {lr}, weight decay = {wd}')\n",
    "        weight_path = f'{base_path}/Q3_weight_adam_{lr}_{wd}'\n",
    "\n",
    "        # load pretrained resnet50 and set the output dimension to 4\n",
    "        model = models.resnet50(pretrained=True)\n",
    "        model.fc = nn.Linear(model.fc.in_features, 4)\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in model.fc.parameters():\n",
    "            param.requires_grad = True\n",
    "        model.to(device)\n",
    "        print(f'model at {device}')\n",
    "\n",
    "        # train\n",
    "        optim = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "        adam_valid[lr][wd] = train(optim, model, weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0.00001   0.00005    0.00010    0.00050\n",
      "0.0000   4.479928  4.224363  4.2429733  4.1592846\n",
      "0.0001  4.6933312  4.403717   4.255934   4.418859\n",
      "0.0010  4.5794396  4.288756  4.1779165   3.964293\n",
      "(x_axis: learning rate)\n",
      "(y_axis: weight decay)\n",
      "\n",
      "minimum validation loss 3.964 at lr=0.0005, wd=0.001\n"
     ]
    }
   ],
   "source": [
    "print(adam_valid)\n",
    "print('(x_axis: learning rate)')\n",
    "print('(y_axis: weight decay)\\n')\n",
    "\n",
    "adam_min_wd = -1\n",
    "adam_min_lr = -1\n",
    "adam_minimum = np.inf\n",
    "for lr in adam_valid.columns:\n",
    "    for wd in adam_valid.index:\n",
    "        if adam_valid[lr][wd] < adam_minimum:\n",
    "            adam_min_wd = wd\n",
    "            adam_min_lr = lr\n",
    "            adam_minimum = adam_valid[lr][wd]\n",
    "print(f'minimum validation loss {adam_minimum:.3f} at lr={adam_min_lr}, wd={adam_min_wd}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load /tmp2/b06705028/sldl/Q3_weight_adam_0.0005_0.001\n",
      "(Adam) test accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "weight_path = f'{base_path}/Q3_weight_adam_{adam_min_lr}_{adam_min_wd}'\n",
    "print(f'load {weight_path}')\n",
    "saved_model = torch.load(weight_path)\n",
    "test_size = len(data['test'])\n",
    "n_correct = 0\n",
    "with torch.no_grad():\n",
    "    for batch, (inputs, targets) in enumerate(dataloaders['test']):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = saved_model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct = (targets==preds).cpu().numpy()\n",
    "        n_correct += np.sum(correct)\n",
    "print(f'(Adam) test accuracy: {n_correct / test_size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test accuracy: 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (row: truth, column: predicted)\n",
      "\n",
      "[[ 1  2  2  4]\n",
      " [ 0 28  3 11]\n",
      " [ 0 15 14 14]\n",
      " [ 0 21  1 30]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "confusion = np.zeros((len(labels), len(labels)))\n",
    "weight_path = '/tmp2/b06705028/sldl/Q3_weight_adam_0.01_0.001'\n",
    "saved_model = torch.load(weight_path)\n",
    "y_truth = np.array([])\n",
    "y_pred = np.array([])\n",
    "with torch.no_grad():\n",
    "    for batch, (inputs, targets) in enumerate(dataloaders['test']):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = saved_model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        y_truth = np.concatenate((y_truth, targets.cpu().numpy()))\n",
    "        y_pred = np.concatenate((y_pred, preds.cpu().numpy()))\n",
    "confusion = confusion_matrix(y_truth, y_pred)\n",
    "print('Confusion Matrix (row: truth, column: predicted)\\n')\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "per class accuracy:\n",
      "blazer: 0.111\n",
      "cardigan: 0.667\n",
      "coat: 0.326\n",
      "jacket: 0.577\n"
     ]
    }
   ],
   "source": [
    "# per class accuracy\n",
    "print('per class accuracy:')\n",
    "for i in range(len(labels)):\n",
    "    total = confusion[i].sum()\n",
    "    correct = confusion[i][i]\n",
    "    print(f'{labels[i]}: {correct / total:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keeping all weights fixed, except the fully connected layer, the overall accuracy is much lower than that we got in Q2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================\n",
      "train SGD lr = 0.001, weight_decay = 0\n",
      "model at cuda\n",
      "epoch 0: train_loss = 43.576, valid_loss = 5.416, best_valid = 5.416\n",
      "epoch 20: train_loss = 42.656, valid_loss = 5.277, best_valid = 4.998\n",
      "early stopping at epoch 28, best_valid = 4.998\n",
      "\n",
      "============================================\n",
      "train SGD lr = 0.001, weight_decay = 0.0001\n",
      "model at cuda\n",
      "epoch 0: train_loss = 43.393, valid_loss = 5.304, best_valid = 5.304\n",
      "epoch 20: train_loss = 42.836, valid_loss = 5.517, best_valid = 5.092\n",
      "early stopping at epoch 38, best_valid = 5.092\n",
      "\n",
      "============================================\n",
      "train SGD lr = 0.001, weight_decay = 0.001\n",
      "model at cuda\n",
      "epoch 0: train_loss = 43.334, valid_loss = 5.378, best_valid = 5.378\n",
      "epoch 20: train_loss = 42.671, valid_loss = 4.991, best_valid = 4.991\n",
      "early stopping at epoch 40, best_valid = 4.991\n",
      "\n",
      "============================================\n",
      "train SGD lr = 0.005, weight_decay = 0\n",
      "model at cuda\n",
      "epoch 0: train_loss = 74.163, valid_loss = 7.658, best_valid = 7.658\n",
      "epoch 20: train_loss = 44.624, valid_loss = 5.159, best_valid = 5.008\n",
      "epoch 40: train_loss = 43.250, valid_loss = 4.955, best_valid = 4.955\n",
      "early stopping at epoch 60, best_valid = 4.955\n",
      "\n",
      "============================================\n",
      "train SGD lr = 0.005, weight_decay = 0.0001\n",
      "model at cuda\n",
      "epoch 0: train_loss = 64.017, valid_loss = 5.480, best_valid = 5.480\n",
      "epoch 20: train_loss = 45.915, valid_loss = 5.182, best_valid = 5.128\n",
      "epoch 40: train_loss = 42.386, valid_loss = 5.070, best_valid = 5.006\n",
      "early stopping at epoch 45, best_valid = 5.006\n",
      "\n",
      "============================================\n",
      "train SGD lr = 0.005, weight_decay = 0.001\n",
      "model at cuda\n",
      "epoch 0: train_loss = 65.096, valid_loss = 6.542, best_valid = 6.542\n",
      "epoch 20: train_loss = 46.839, valid_loss = 5.153, best_valid = 4.902\n",
      "early stopping at epoch 31, best_valid = 4.902\n",
      "\n",
      "============================================\n",
      "train SGD lr = 0.01, weight_decay = 0\n",
      "model at cuda\n",
      "epoch 0: train_loss = 116.131, valid_loss = 5.783, best_valid = 5.783\n",
      "epoch 20: train_loss = 44.064, valid_loss = 5.213, best_valid = 5.077\n",
      "epoch 40: train_loss = 43.498, valid_loss = 5.098, best_valid = 4.914\n",
      "early stopping at epoch 44, best_valid = 4.914\n",
      "\n",
      "============================================\n",
      "train SGD lr = 0.01, weight_decay = 0.0001\n",
      "model at cuda\n",
      "epoch 0: train_loss = 117.090, valid_loss = 8.666, best_valid = 8.666\n",
      "epoch 20: train_loss = 43.730, valid_loss = 4.976, best_valid = 4.976\n",
      "early stopping at epoch 40, best_valid = 4.976\n",
      "\n",
      "============================================\n",
      "train SGD lr = 0.01, weight_decay = 0.001\n",
      "model at cuda\n",
      "epoch 0: train_loss = 104.743, valid_loss = 6.344, best_valid = 6.344\n",
      "epoch 20: train_loss = 45.494, valid_loss = 5.110, best_valid = 4.919\n",
      "early stopping at epoch 36, best_valid = 4.919\n",
      "\n",
      "============================================\n",
      "train SGD lr = 0.05, weight_decay = 0\n",
      "model at cuda\n",
      "epoch 0: train_loss = 226.285, valid_loss = 6.171, best_valid = 6.171\n",
      "epoch 20: train_loss = 42.829, valid_loss = 20.515, best_valid = 5.082\n",
      "epoch 40: train_loss = 41.196, valid_loss = 5.125, best_valid = 4.944\n",
      "early stopping at epoch 42, best_valid = 4.944\n",
      "\n",
      "============================================\n",
      "train SGD lr = 0.05, weight_decay = 0.0001\n",
      "model at cuda\n",
      "epoch 0: train_loss = 180.810, valid_loss = 5.801, best_valid = 5.801\n",
      "epoch 20: train_loss = 42.594, valid_loss = 5.170, best_valid = 4.947\n",
      "epoch 40: train_loss = 41.370, valid_loss = 5.262, best_valid = 4.905\n",
      "early stopping at epoch 49, best_valid = 4.905\n",
      "\n",
      "============================================\n",
      "train SGD lr = 0.05, weight_decay = 0.001\n",
      "model at cuda\n",
      "epoch 0: train_loss = 165.960, valid_loss = 5.182, best_valid = 5.182\n",
      "epoch 20: train_loss = 41.502, valid_loss = 5.090, best_valid = 4.972\n",
      "epoch 40: train_loss = 44.781, valid_loss = 17.149, best_valid = 4.940\n",
      "early stopping at epoch 47, best_valid = 4.940\n"
     ]
    }
   ],
   "source": [
    "sgd_valid = pd.DataFrame(columns=all_lr, index=all_wd)\n",
    "\n",
    "for lr in all_lr:\n",
    "    for wd in all_wd:\n",
    "        print('\\n============================================')\n",
    "        print(f'train SGD lr = {lr}, weight_decay = {wd}')\n",
    "        weight_path = f'{base_path}/Q4_weight_{lr}_{wd}'\n",
    "\n",
    "        # load pretrained resnet50 and set the output dimension to 4\n",
    "        model = models.resnet50(pretrained=False)\n",
    "        model.fc = nn.Linear(model.fc.in_features, 4)\n",
    "        model.to(device)\n",
    "        print(f'model at {device}')\n",
    "\n",
    "        # train\n",
    "        optim = torch.optim.SGD(model.parameters(), lr=lr, weight_decay=wd)\n",
    "        valid_loss = train(optim, model, weight_path)\n",
    "        sgd_valid[lr][wd] = valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0.001      0.005      0.010      0.050\n",
      "0.0000   4.998086  4.9553504  4.9137764  4.9439445\n",
      "0.0001  5.0923233  5.0064526   4.976336  4.9054356\n",
      "0.0010   4.991056  4.9016933  4.9188795  4.9398346\n",
      "(x_axis: learning rate)\n",
      "(y_axis: weight decay)\n",
      "\n",
      "minimum validation loss 4.902 at lr=0.005, wd=0.001\n"
     ]
    }
   ],
   "source": [
    "print(sgd_valid)\n",
    "print('(x_axis: learning rate)')\n",
    "print('(y_axis: weight decay)\\n')\n",
    "\n",
    "sgd_min_wd = -1\n",
    "sgd_min_lr = -1\n",
    "sgd_minimum = np.inf\n",
    "for lr in sgd_valid.columns:\n",
    "    for wd in sgd_valid.index:\n",
    "        if sgd_valid[lr][wd] < sgd_minimum:\n",
    "            sgd_min_wd = wd\n",
    "            sgd_min_lr = lr\n",
    "            sgd_minimum = sgd_valid[lr][wd]\n",
    "print(f'minimum validation loss {sgd_minimum:.3f} at lr={sgd_min_lr}, wd={sgd_min_wd}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(SGD) test accuracy: 0.3835616438356164\n"
     ]
    }
   ],
   "source": [
    "weight_path = f'{base_path}/Q4_weight_{sgd_min_lr}_{sgd_min_wd}'\n",
    "saved_model = torch.load(weight_path)\n",
    "test_size = len(data['test'])\n",
    "n_correct = 0\n",
    "with torch.no_grad():\n",
    "    for batch, (inputs, targets) in enumerate(dataloaders['test']):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = saved_model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct = (targets==preds).cpu().numpy()\n",
    "        n_correct += np.sum(correct)\n",
    "print(f'(SGD) test accuracy: {n_correct / test_size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================\n",
      "train Adam lr = 1e-05, weight decay = 0\n",
      "model at cuda\n",
      "epoch 0: train_loss = 45.448, valid_loss = 5.402, best_valid = 5.402\n",
      "epoch 20: train_loss = 41.439, valid_loss = 5.256, best_valid = 5.064\n",
      "epoch 40: train_loss = 40.434, valid_loss = 5.726, best_valid = 4.974\n",
      "epoch 60: train_loss = 40.162, valid_loss = 5.133, best_valid = 4.867\n",
      "early stopping at epoch 63, best_valid = 4.867\n",
      "\n",
      "============================================\n",
      "train Adam lr = 1e-05, weight decay = 0.0001\n",
      "model at cuda\n",
      "epoch 0: train_loss = 52.293, valid_loss = 6.334, best_valid = 6.334\n",
      "epoch 20: train_loss = 41.023, valid_loss = 5.010, best_valid = 4.962\n",
      "epoch 40: train_loss = 40.788, valid_loss = 5.458, best_valid = 4.884\n",
      "early stopping at epoch 42, best_valid = 4.884\n",
      "\n",
      "============================================\n",
      "train Adam lr = 1e-05, weight decay = 0.001\n",
      "model at cuda\n",
      "epoch 0: train_loss = 46.793, valid_loss = 5.334, best_valid = 5.334\n",
      "epoch 20: train_loss = 41.234, valid_loss = 5.314, best_valid = 5.075\n",
      "epoch 40: train_loss = 40.747, valid_loss = 5.178, best_valid = 5.032\n",
      "early stopping at epoch 45, best_valid = 5.032\n",
      "\n",
      "============================================\n",
      "train Adam lr = 5e-05, weight decay = 0\n",
      "model at cuda\n",
      "epoch 0: train_loss = 43.551, valid_loss = 5.381, best_valid = 5.381\n",
      "epoch 20: train_loss = 41.471, valid_loss = 5.144, best_valid = 4.929\n",
      "early stopping at epoch 33, best_valid = 4.929\n",
      "\n",
      "============================================\n",
      "train Adam lr = 5e-05, weight decay = 0.0001\n",
      "model at cuda\n",
      "epoch 0: train_loss = 45.544, valid_loss = 5.850, best_valid = 5.850\n",
      "epoch 20: train_loss = 41.418, valid_loss = 5.246, best_valid = 4.907\n",
      "early stopping at epoch 34, best_valid = 4.907\n",
      "\n",
      "============================================\n",
      "train Adam lr = 5e-05, weight decay = 0.001\n",
      "model at cuda\n",
      "epoch 0: train_loss = 43.082, valid_loss = 5.415, best_valid = 5.415\n",
      "epoch 20: train_loss = 40.543, valid_loss = 5.546, best_valid = 5.051\n",
      "early stopping at epoch 21, best_valid = 5.051\n",
      "\n",
      "============================================\n",
      "train Adam lr = 0.0001, weight decay = 0\n",
      "model at cuda\n",
      "epoch 0: train_loss = 43.860, valid_loss = 6.154, best_valid = 6.154\n",
      "epoch 20: train_loss = 41.063, valid_loss = 5.204, best_valid = 4.997\n",
      "epoch 40: train_loss = 40.831, valid_loss = 5.267, best_valid = 4.950\n",
      "early stopping at epoch 52, best_valid = 4.950\n",
      "\n",
      "============================================\n",
      "train Adam lr = 0.0001, weight decay = 0.0001\n",
      "model at cuda\n",
      "epoch 0: train_loss = 44.263, valid_loss = 5.556, best_valid = 5.556\n",
      "epoch 20: train_loss = 41.487, valid_loss = 4.996, best_valid = 4.996\n",
      "early stopping at epoch 40, best_valid = 4.996\n",
      "\n",
      "============================================\n",
      "train Adam lr = 0.0001, weight decay = 0.001\n",
      "model at cuda\n",
      "epoch 0: train_loss = 43.683, valid_loss = 6.257, best_valid = 6.257\n",
      "epoch 20: train_loss = 41.352, valid_loss = 5.145, best_valid = 5.135\n",
      "epoch 40: train_loss = 39.883, valid_loss = 5.013, best_valid = 5.013\n",
      "epoch 60: train_loss = 36.418, valid_loss = 6.668, best_valid = 4.886\n",
      "early stopping at epoch 79, best_valid = 4.886\n",
      "\n",
      "============================================\n",
      "train Adam lr = 0.0005, weight decay = 0\n",
      "model at cuda\n",
      "epoch 0: train_loss = 49.843, valid_loss = 6.104, best_valid = 6.104\n",
      "epoch 20: train_loss = 40.159, valid_loss = 5.268, best_valid = 4.940\n",
      "early stopping at epoch 38, best_valid = 4.940\n",
      "\n",
      "============================================\n",
      "train Adam lr = 0.0005, weight decay = 0.0001\n",
      "model at cuda\n",
      "epoch 0: train_loss = 48.972, valid_loss = 6.377, best_valid = 6.377\n",
      "epoch 20: train_loss = 40.017, valid_loss = 5.053, best_valid = 5.038\n",
      "early stopping at epoch 22, best_valid = 5.038\n",
      "\n",
      "============================================\n",
      "train Adam lr = 0.0005, weight decay = 0.001\n",
      "model at cuda\n",
      "epoch 0: train_loss = 50.120, valid_loss = 6.467, best_valid = 6.467\n",
      "epoch 20: train_loss = 40.814, valid_loss = 5.548, best_valid = 5.118\n",
      "epoch 40: train_loss = 38.973, valid_loss = 5.119, best_valid = 4.972\n",
      "early stopping at epoch 44, best_valid = 4.972\n"
     ]
    }
   ],
   "source": [
    "all_lr = [0.00001, 0.00005, 0.0001, 0.0005]\n",
    "all_wd = [0, 0.0001, 0.001]\n",
    "adam_valid = pd.DataFrame(columns=all_lr, index=all_wd)\n",
    "\n",
    "for lr in all_lr:\n",
    "    for wd in all_wd:\n",
    "        print('\\n============================================')\n",
    "        print(f'train Adam lr = {lr}, weight decay = {wd}')\n",
    "        weight_path = f'{base_path}/Q4_weight_adam_{lr}_{wd}'\n",
    "\n",
    "        # load pretrained resnet50 and set the output dimension to 4\n",
    "        model = models.resnet50(pretrained=False)\n",
    "        model.fc = nn.Linear(model.fc.in_features, 4)\n",
    "        model.to(device)\n",
    "        print(f'model at {device}')\n",
    "\n",
    "        # train\n",
    "        optim = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "        adam_valid[lr][wd] = train(optim, model, weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0.00001   0.00005    0.00010    0.00050\n",
      "0.0000  4.8669505  4.928935  4.9500265   4.939928\n",
      "0.0001  4.8838434  4.906565  4.9956007  5.0377192\n",
      "0.0010   5.031926  5.050787   4.886034   4.972141\n",
      "(x_axis: learning rate)\n",
      "(y_axis: weight decay)\n",
      "\n",
      "minimum validation loss 4.867 at lr=1e-05, wd=0.0\n"
     ]
    }
   ],
   "source": [
    "print(adam_valid)\n",
    "print('(x_axis: learning rate)')\n",
    "print('(y_axis: weight decay)\\n')\n",
    "\n",
    "adam_min_wd = -1\n",
    "adam_min_lr = -1\n",
    "adam_minimum = np.inf\n",
    "for lr in adam_valid.columns:\n",
    "    for wd in adam_valid.index:\n",
    "        if adam_valid[lr][wd] < adam_minimum:\n",
    "            adam_min_wd = wd\n",
    "            adam_min_lr = lr\n",
    "            adam_minimum = adam_valid[lr][wd]\n",
    "print(f'minimum validation loss {adam_minimum:.3f} at lr={adam_min_lr}, wd={adam_min_wd}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load /tmp2/b06705028/sldl/Q4_weight_adam_1e-05_0\n",
      "(Adam) test accuracy: 0.3287671232876712\n"
     ]
    }
   ],
   "source": [
    "weight_path = f'{base_path}/Q4_weight_adam_{adam_min_lr}_{adam_min_wd}'\n",
    "print(f'load {weight_path}')\n",
    "saved_model = torch.load(weight_path)\n",
    "test_size = len(data['test'])\n",
    "n_correct = 0\n",
    "with torch.no_grad():\n",
    "    for batch, (inputs, targets) in enumerate(dataloaders['test']):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = saved_model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct = (targets==preds).cpu().numpy()\n",
    "        n_correct += np.sum(correct)\n",
    "print(f'(Adam) test accuracy: {n_correct / test_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (row: truth, column: predicted)\n",
      "\n",
      "[[ 0  6  0  3]\n",
      " [ 0 27  0 15]\n",
      " [ 0 27  0 16]\n",
      " [ 0 23  0 29]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "confusion = np.zeros((len(labels), len(labels)))\n",
    "weight_path = '/tmp2/b06705028/sldl/Q4_weight_0.005_0.001'\n",
    "saved_model = torch.load(weight_path)\n",
    "y_truth = np.array([])\n",
    "y_pred = np.array([])\n",
    "with torch.no_grad():\n",
    "    for batch, (inputs, targets) in enumerate(dataloaders['test']):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = saved_model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        y_truth = np.concatenate((y_truth, targets.cpu().numpy()))\n",
    "        y_pred = np.concatenate((y_pred, preds.cpu().numpy()))\n",
    "confusion = confusion_matrix(y_truth, y_pred)\n",
    "print('Confusion Matrix (row: truth, column: predicted)\\n')\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "per class accuracy:\n",
      "blazer: 0.000\n",
      "cardigan: 0.643\n",
      "coat: 0.000\n",
      "jacket: 0.558\n"
     ]
    }
   ],
   "source": [
    "# per class accuracy\n",
    "print('per class accuracy:')\n",
    "for i in range(len(labels)):\n",
    "    total = confusion[i].sum()\n",
    "    correct = confusion[i][i]\n",
    "    print(f'{labels[i]}: {correct / total:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the three models is Q2 > Q3 > Q4. This indicates that the pretrained model is effective in enhancing the model performance. Moreover, updating all model weights allows the model to fit better than the case that only the fully connected layer is modified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
