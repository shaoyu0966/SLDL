{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Learning and Deep Learning HW5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['train', 'valid' ,'test']\n",
    "labels = ['blazer', 'cardigan', 'coat', 'jacket']\n",
    "base_path = './photos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      blazer cardigan coat jacket   total\n",
      "train     98      238  297    412  1045.0\n",
      "valid      7       36   27     35   105.0\n",
      "test       9       42   43     52   146.0\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=labels, index=datasets)\n",
    "for ds in datasets:\n",
    "    for lb in labels:\n",
    "        df[lb][ds] = len(os.listdir(f'{base_path}/{ds}/{lb}/'))\n",
    "df['total'] = df.sum(axis=1)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio:\n",
      "         blazer  cardigan      coat    jacket\n",
      "train  0.093780  0.227751  0.284211  0.394258\n",
      "valid  0.066667  0.342857  0.257143  0.333333\n",
      "test   0.061644  0.287671  0.294521  0.356164\n"
     ]
    }
   ],
   "source": [
    "print('Ratio:')\n",
    "df = df.drop(['total'], axis=1)\n",
    "print (df.div(df.sum(axis=1), axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the number of instances of each image type, I suggest that the accuracy of the classification task will be jacket > coat > cardigan > blazer. This follows the hypothesis that larger number of instances in training set causes higher classification accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image transformations\n",
    "image_transforms = {\n",
    "    'train':\n",
    "    transforms.Compose([\n",
    "        transforms.Resize(size=256),\n",
    "        transforms.RandomResizedCrop(size=(224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(degrees=20),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    \n",
    "    'valid':\n",
    "    transforms.Compose([\n",
    "        transforms.Resize(size=256),\n",
    "        transforms.CenterCrop(size=224)\n",
    "    ]),\n",
    "    \n",
    "    'test':\n",
    "    transforms.Compose([\n",
    "        transforms.Resize(size=256),\n",
    "        transforms.CenterCrop(size=224)\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets from folders\n",
    "data = {\n",
    "    'train':\n",
    "        ImageFolder(root=f'{base_path}/train/', transform=image_transforms['train']),\n",
    "    'valid':\n",
    "        ImageFolder(root=f'{base_path}/valid/', transform=image_transforms['valid']),\n",
    "    'test':\n",
    "        ImageFolder(root=f'{base_path}/test/', transform=image_transforms['test'])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader\n",
    "batch_size = 32\n",
    "max_epoch = 200\n",
    "early_stop_patient = 20\n",
    "dataloaders = {\n",
    "    'train':\n",
    "        DataLoader(data['train'], batch_size=batch_size, shuffle=True, num_workers=10),\n",
    "    'valid':\n",
    "        DataLoader(data['valid'], batch_size=batch_size, shuffle=True, num_workers=10),\n",
    "    'test':\n",
    "        DataLoader(data['test'], batch_size=batch_size, shuffle=True, num_workers=10)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pretrained resnet50 and set the output dimension to 4\n",
    "model = models.resnet50(pretrained=True)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "model.fc = nn.Linear(model.fc.in_features, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
