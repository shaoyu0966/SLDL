{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Learning and Deep Learning HW4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape =  (463715, 90)\n",
      "X_subtrain shape =  (417344, 90)\n",
      "X_valid shape =  (46371, 90)\n",
      "\n",
      "Y_train shape =  (463715,)\n",
      "Y_subtrain shape =  (417344,)\n",
      "Y_valid shape =  (46371,)\n",
      "\n",
      "X_test shape =  (51630, 90)\n",
      "Y_test shape =  (51630,)\n"
     ]
    }
   ],
   "source": [
    "# load packages\n",
    "import pickle\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline\n",
    "\n",
    "# load data\n",
    "with open('msd_full.pickle', 'rb') as fh1:\n",
    "    msd_data = pickle.load(fh1)\n",
    "\n",
    "doscaling = 1\n",
    "if doscaling == 1:\n",
    "    xscaler = preprocessing.StandardScaler().fit(msd_data['X_train'])\n",
    "    # standardize feature values\n",
    "    X_train = xscaler.transform(msd_data['X_train'])\n",
    "    X_test = xscaler.transform(msd_data['X_test'])\n",
    "else:\n",
    "    X_train = msd_data['X_train']\n",
    "    X_test = msd_data['X_test']\n",
    "\n",
    "Y_train = msd_data['Y_train']\n",
    "Y_test = msd_data['Y_test'].astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "y_mean = Y_train.mean()\n",
    "Y_train_keep = Y_train.copy()\n",
    "Y_test_keep = Y_test.copy()\n",
    "Y_train = Y_train - y_mean\n",
    "Y_test = Y_test - y_mean\n",
    "\n",
    "\n",
    "# validation is the last 10% of training, subtraining is the first 90% of training\n",
    "nvalid = int(X_train.shape[0] * 0.1)\n",
    "nsubtrain = X_train.shape[0] - nvalid\n",
    "\n",
    "X_subtrain = X_train[0:nsubtrain, :].astype('float32')\n",
    "X_valid = X_train[nsubtrain:, :].astype('float32')\n",
    "Y_subtrain = Y_train[0:nsubtrain].astype('float32')\n",
    "Y_valid = Y_train[nsubtrain:].astype('float32')\n",
    "\n",
    "Y_subtrain_keep = Y_train_keep[0:nsubtrain].astype('float32')\n",
    "Y_valid_keep = Y_train_keep[nsubtrain:].astype('float32')\n",
    "\n",
    "print(\"X_train shape = \", X_train.shape)\n",
    "print(\"X_subtrain shape = \", X_subtrain.shape)\n",
    "print(\"X_valid shape = \", X_valid.shape)\n",
    "print()\n",
    "print(\"Y_train shape = \", Y_train.shape)\n",
    "print(\"Y_subtrain shape = \", Y_subtrain.shape)\n",
    "print(\"Y_valid shape = \", Y_valid.shape)\n",
    "print()\n",
    "print(\"X_test shape = \", X_test.shape)\n",
    "print(\"Y_test shape = \", Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. Oridinary Least Square (OLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "ols = sm.OLS(Y_train, X_train, hasconst=True)\n",
    "ols_result = ols.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first 5 parameters: [ 5.30975265 -2.88088114 -1.53234348  0.05737583 -0.33952889]\n"
     ]
    }
   ],
   "source": [
    "print(f'The first 5 parameters: {ols_result.params[:5]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted Y is [-5.81070695  0.03250657  5.13960445 ... -1.39829429 -0.26047668\n",
      "  0.05193056]\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "Y_predict = ols_result.predict(X_test)\n",
    "print(f'The predicted Y is {Y_predict}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 9.510160684544402\n"
     ]
    }
   ],
   "source": [
    "# RMSE\n",
    "print(f'RMSE = {mean_squared_error(Y_test, Y_predict, squared=False)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. MLP with Four Hidden Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 1.7.1rc2\n",
      "using cuda\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils import data\n",
    "import os\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "print('torch version:', torch.__version__)\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'using {device}')\n",
    "print(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataset\n",
    "class Dataset(data.Dataset):\n",
    "    \n",
    "  def __init__(self, Xnp, Ynp):\n",
    "        self.labels = Ynp\n",
    "        self.nobs = Xnp.shape[0]        \n",
    "        self.Xnp = Xnp\n",
    "        self.Ynp = Ynp\n",
    "        \n",
    "  def __len__(self):\n",
    "        return self.nobs\n",
    "    \n",
    "  def __getitem__(self, index):     \n",
    "        X = self.Xnp[index]\n",
    "        y = self.Ynp[index]\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subtrain length 417344\n",
      "valid length 46371\n",
      "test length 51630\n"
     ]
    }
   ],
   "source": [
    "# create dataloader\n",
    "subtrain_set = Dataset(X_subtrain, Y_subtrain)    \n",
    "valid_set = Dataset(X_valid, Y_valid)\n",
    "test_set = Dataset(X_test, Y_test)\n",
    "print('subtrain length', len(subtrain_set))\n",
    "print('valid length', len(valid_set))\n",
    "print('test length', len(test_set))\n",
    "\n",
    "batch_size = 1000\n",
    "subtrain_loader = data.DataLoader(subtrain_set, batch_size=batch_size)\n",
    "valid_loader = data.DataLoader(valid_set, batch_size=batch_size)\n",
    "test_loader = data.DataLoader(test_set, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=90, out_features=45, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=45, out_features=45, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=45, out_features=45, bias=True)\n",
       "  (5): ReLU()\n",
       "  (6): Linear(in_features=45, out_features=45, bias=True)\n",
       "  (7): ReLU()\n",
       "  (8): Linear(in_features=45, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create MLP model\n",
    "d_hidden = 45\n",
    "d_input = subtrain_set.Xnp.shape[1]\n",
    "d_output = 1\n",
    "\n",
    "MLP = torch.nn.Sequential(\n",
    "    torch.nn.Linear(d_input, d_hidden),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(d_hidden, d_hidden),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(d_hidden, d_hidden),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(d_hidden, d_hidden),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(d_hidden, d_output)\n",
    ")\n",
    "MLP.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer\n",
    "lr = 0.00001\n",
    "momentum = 0\n",
    "weight_decay = 0\n",
    "optimizer = torch.optim.SGD(MLP.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "\n",
    "# loss\n",
    "loss_func = torch.nn.MSELoss(reduction='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "\n",
    "def RMSE(data_loader):\n",
    "    n_obs = 0\n",
    "    sse = 0\n",
    "    for _batch, (_inputs, _targets) in enumerate(subtrain_loader):\n",
    "        _targets = _targets.reshape((-1, 1))\n",
    "        _inputs, _targets = _inputs.to(device), _targets.to(device)\n",
    "        _outputs = MLP(_inputs)\n",
    "        n_obs += _targets.shape[0]\n",
    "        sse += (_targets - _outputs).pow(2).sum(0)\n",
    "    return np.sqrt(sse.cpu().numpy()[0] / n_obs)\n",
    "\n",
    "    \n",
    "def train(MLP, max_epoch, max_step, valid_interval, weight_path, train_rmse=False):\n",
    "    \n",
    "    step_count = 0\n",
    "    best_step_count = 0\n",
    "    best_valid_rmse = np.inf\n",
    "    all_train_rmse = []\n",
    "    all_valid_rmse = []\n",
    "    all_step = []\n",
    "\n",
    "    for epoch in range(1, max_epoch+1):\n",
    "        for batch, (inputs, targets) in enumerate(subtrain_loader):\n",
    "\n",
    "            targets = targets.reshape((-1, 1))\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            MLP.to(device)\n",
    "            MLP.train()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = MLP(inputs)\n",
    "            loss = loss_func(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            step_count += 1\n",
    "\n",
    "            # check train/validation RMSE\n",
    "            if (step_count % valid_interval == 0):\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    # subtrain, validation RMSE\n",
    "                    if train_rmse:\n",
    "                        train_rmse = RMSE(subtrain_loader)\n",
    "                        all_train_rmse.append(train_rmse)\n",
    "                    valid_rmse = RMSE(valid_loader)\n",
    "                    all_valid_rmse.append(valid_rmse)\n",
    "                    all_step.append(step_count)\n",
    "\n",
    "                    # update weight\n",
    "                    if valid_rmse < best_valid_rmse:\n",
    "                        best_step_count = step_count\n",
    "                        best_valid_rmse = valid_rmse\n",
    "                        torch.save(MLP.state_dict(), weight_path)\n",
    "                        \n",
    "                    # early stopping\n",
    "                    elif (step_count - best_step_count >= max_step):\n",
    "                        print(f'early stopping, step {step_count}, validation RMSE = {valid_rmse}')\n",
    "                        return all_step, all_train_rmse, all_valid_rmse\n",
    "\n",
    "        print(f'Epoch {epoch}, Step {step_count}: Loss = {loss.item()}, best_valid_rmse = {best_valid_rmse}')\n",
    "    return all_step, all_train_rmse, all_valid_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 418: Loss = 35491.0, best_valid_rmse = 8.9548867520085\n",
      "Epoch 2, Step 836: Loss = 34541.1796875, best_valid_rmse = 8.713036698589338\n",
      "Epoch 3, Step 1254: Loss = 34125.15625, best_valid_rmse = 8.671243370223578\n"
     ]
    }
   ],
   "source": [
    "all_step, all_train_rmse, all_valid_rmse = train(MLP=MLP, max_epoch=100, max_step=5000, valid_interval=100, weight_path='./MLP45_weight', train_rmse=True)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plot subtrain / validation RMSE\n",
    "plt.plot(all_step, all_train_rmse, c='b', label='Training RMSE')\n",
    "plt.plot(all_step, all_valid_rmse, c='r', label='Validation RMSE')\n",
    "plt.legend()\n",
    "plt.xlabel('Batch')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('Training & Validation RMSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test RMSE\n",
    "with torch.no_grad():\n",
    "    test_rmse = RMSE(test_loader)\n",
    "print(f'Test RMSE = {test_rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3. H = 90, 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
