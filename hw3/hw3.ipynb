{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Learning and Deep Learning HW3\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1\n",
    "\n",
    "#### Q1.1\n",
    "\n",
    "1. Read the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  gname  sex  fold\n",
      "0    承憲    1     9\n",
      "1    均平    1     7\n",
      "2    思安    0     6\n",
      "3    佑誠    1     3\n",
      "4    乃馨    0     0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn import preprocessing\n",
    "\n",
    "df = pd.read_csv('./ds/namesex_data_v2.csv', sep=',')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Split the dataset into training, validation, stack, and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: (7483,), y_train: (7483,)\n",
      "x_valid: (1110,), y_valid: (1110,)\n",
      "x_stack: (1073,), y_stack: (1073,)\n",
      "x_test: (1064,), y_test: (1064,)\n"
     ]
    }
   ],
   "source": [
    "# split by fold value\n",
    "train = df[df['fold'] <= 6]\n",
    "valid = df[df['fold'] == 7]\n",
    "stack = df[df['fold'] == 8]\n",
    "test = df[df['fold'] == 9]\n",
    "    \n",
    "train = train.reset_index()\n",
    "valid = valid.reset_index()\n",
    "stack = stack.reset_index()\n",
    "test = test.reset_index()\n",
    "\n",
    "# split x, y\n",
    "x_train = train['gname']\n",
    "y_train = train['sex'].to_numpy()\n",
    "x_valid = valid['gname']\n",
    "y_valid = valid['sex'].to_numpy()\n",
    "x_stack = stack['gname']\n",
    "y_stack = stack['sex'].to_numpy()\n",
    "x_test = test['gname']\n",
    "y_test = test['sex'].to_numpy()\n",
    "\n",
    "print(f'x_train: {x_train.shape}, y_train: {y_train.shape}')\n",
    "print(f'x_valid: {x_valid.shape}, y_valid: {y_valid.shape}')\n",
    "print(f'x_stack: {x_stack.shape}, y_stack: {y_stack.shape}')\n",
    "print(f'x_test: {x_test.shape}, y_test: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Apply one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of feature: 1630\n"
     ]
    }
   ],
   "source": [
    "feature = list()\n",
    "for name in list(x_train.to_numpy()):\n",
    "    if len(name) > 1:\n",
    "        feature += list(name)\n",
    "    feature.append(name)\n",
    "feature_set = set(feature) - set(' ')\n",
    "feature_count = dict((f, feature.count(f)) for f in feature_set)\n",
    "feature_count = dict(filter(lambda pair: pair[1] >= 2, feature_count.items()))\n",
    "feature = list(feature_count.keys())\n",
    "feature.append('_Other_Feature_')\n",
    "print(f'# of feature: {len(feature)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: (7483, 1630), y_train: (7483,)\n",
      "x_valid: (1110, 1630), y_valid: (1110,)\n",
      "x_stack: (1073, 1630), y_stack: (1073,)\n",
      "x_test: (1064, 1630), y_test: (1064,)\n"
     ]
    }
   ],
   "source": [
    "def oneHot(df):\n",
    "    one_hot = pd.DataFrame(0, index=np.arange(df.shape[0]), columns=feature)\n",
    "    for idx in range(df.shape[0]):\n",
    "        # create feature list\n",
    "        f_list = list(df[idx])\n",
    "        if len(df[idx]) > 1:\n",
    "            f_list.append(df[idx])\n",
    "        cnt = 0\n",
    "        # label\n",
    "        for f in f_list:\n",
    "            if f in feature:\n",
    "                one_hot[f][idx] = 1\n",
    "                cnt += 1\n",
    "        # label other feature\n",
    "        if cnt < len(f_list):\n",
    "            one_hot['_Other_Feature_'][idx] = 1\n",
    "    return one_hot, one_hot.columns\n",
    "\n",
    "x_train, x_train_col = oneHot(x_train)\n",
    "x_valid, x_valid_col = oneHot(x_valid)\n",
    "x_stack, x_stack_col = oneHot(x_stack)\n",
    "x_test, x_test_col = oneHot(x_test)\n",
    "\n",
    "print(f'x_train: {x_train.shape}, y_train: {y_train.shape}')\n",
    "print(f'x_valid: {x_valid.shape}, y_valid: {y_valid.shape}')\n",
    "print(f'x_stack: {x_stack.shape}, y_stack: {y_stack.shape}')\n",
    "print(f'x_test: {x_test.shape}, y_test: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1.2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tune c from [1.00000000e-04 2.33572147e-04 5.45559478e-04 1.27427499e-03\n",
      " 2.97635144e-03 6.95192796e-03 1.62377674e-02 3.79269019e-02\n",
      " 8.85866790e-02 2.06913808e-01 4.83293024e-01 1.12883789e+00\n",
      " 2.63665090e+00 6.15848211e+00 1.43844989e+01 3.35981829e+01\n",
      " 7.84759970e+01 1.83298071e+02 4.28133240e+02 1.00000000e+03]\n",
      "c: 0.0001, f1 score: 0.0\n",
      "c: 0.00023357214690901214, f1 score: 0.0\n",
      "c: 0.000545559478116852, f1 score: 0.007532956685499058\n",
      "c: 0.0012742749857031334, f1 score: 0.3879699248120301\n",
      "c: 0.002976351441631319, f1 score: 0.7491785323110624\n",
      "c: 0.0069519279617756054, f1 score: 0.8430232558139534\n",
      "c: 0.01623776739188721, f1 score: 0.8638941398865785\n",
      "c: 0.0379269019073225, f1 score: 0.876763875823142\n",
      "c: 0.08858667904100823, f1 score: 0.887841658812441\n",
      "c: 0.2069138081114788, f1 score: 0.8895184135977338\n",
      "c: 0.4832930238571752, f1 score: 0.8932955618508026\n",
      "c: 1.1288378916846884, f1 score: 0.8945386064030133\n",
      "c: 2.6366508987303554, f1 score: 0.8953817153628653\n",
      "c: 6.1584821106602545, f1 score: 0.8930936613055818\n",
      "c: 14.38449888287663, f1 score: 0.8972667295004714\n",
      "c: 33.59818286283781, f1 score: 0.8962264150943396\n",
      "c: 78.47599703514607, f1 score: 0.8981132075471698\n",
      "c: 183.29807108324337, f1 score: 0.8962264150943396\n",
      "c: 428.1332398719387, f1 score: 0.8960302457466919\n",
      "c: 1000.0, f1 score: 0.8968779564806055\n",
      "best c: 78.47599703514607\n",
      "best f1: 0.8981132075471698\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score\n",
    "\n",
    "# tune coefficient c\n",
    "c_coef = np.geomspace(0.0001, 1000, num=20)\n",
    "print(f'tune c from {c_coef}')\n",
    "\n",
    "best_c = 0.0001\n",
    "best_f1 = -np.inf\n",
    "for c in c_coef:\n",
    "    clf = LogisticRegression(C=c, max_iter=1000).fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_valid)\n",
    "    f1 = f1_score(y_valid, y_pred)\n",
    "    print(f'c: {c}, f1 score: {f1}')\n",
    "    \n",
    "    if f1 > best_f1:\n",
    "        best_c = c\n",
    "        best_f1 = f1\n",
    "print(f'best c: {best_c}')\n",
    "print(f'best f1: {best_f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 0.8843984962406015\n",
      "test precision: 0.8596837944664032\n",
      "test recall: 0.893223819301848\n",
      "test f1_score: 0.8761329305135951\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "x_train_valid = np.concatenate((x_train, x_valid), axis=0)\n",
    "y_train_valid = np.concatenate((y_train, y_valid), axis=0)\n",
    "clf_log = LogisticRegression(C=best_c, max_iter=1000).fit(x_train_valid, y_train_valid)\n",
    "y_pred = clf_log.predict(x_test)\n",
    "print(f'test accuracy: {accuracy_score(y_test, y_pred)}')\n",
    "print(f'test precision: {precision_score(y_test, y_pred)}')\n",
    "print(f'test recall: {recall_score(y_test, y_pred)}')\n",
    "print(f'test f1_score: {f1_score(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 features with max absolute coefficient:\n",
      "蓉 -7.5942162930202\n",
      "松 7.608294885526651\n",
      "靜 -7.6519143233262765\n",
      "卉 -7.808083457250313\n",
      "絃 -7.841816159659198\n",
      "嵐 -7.880203977123571\n",
      "潔 -8.029886865729008\n",
      "綾 -8.130090566174225\n",
      "婕 -8.14749925578164\n",
      "妤 -8.164416288312571\n",
      "鋒 8.211084144120642\n",
      "薇 -8.212371925903277\n",
      "萱 -8.28458707512602\n",
      "美 -8.313903559289411\n",
      "婷 -8.387863938831076\n",
      "凌 -8.442735688873352\n",
      "雯 -8.474067339078648\n",
      "玲 -8.63132275844053\n",
      "森 8.691386405478989\n",
      "傑 9.268250666442409\n"
     ]
    }
   ],
   "source": [
    "coef = clf_log.coef_[0]\n",
    "abs_coef = np.abs(coef)\n",
    "max20 = abs_coef.argsort()[-20:]\n",
    "print('20 features with max absolute coefficient:')\n",
    "for idx in max20:\n",
    "    print(x_test_col[idx], coef[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy, precision, recall, f1_score are all above 0.8. The prediction performs well.\n",
    "\n",
    "As for the features, we can see that words often seen in boys' names have positive coefficients, while those often seen in girls' names have negative coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tune n_estimators from [   5    9   16   29   52   94  170  308  555 1000]\n",
      "n_estimators: 5, f1 score: 0.8528015194681862\n",
      "n_estimators: 9, f1 score: 0.8666666666666667\n",
      "n_estimators: 16, f1 score: 0.8618357487922705\n",
      "n_estimators: 29, f1 score: 0.867816091954023\n",
      "n_estimators: 52, f1 score: 0.8606870229007634\n",
      "n_estimators: 94, f1 score: 0.8618357487922705\n",
      "n_estimators: 170, f1 score: 0.8694817658349328\n",
      "n_estimators: 308, f1 score: 0.8604206500956023\n",
      "n_estimators: 555, f1 score: 0.8673076923076922\n",
      "n_estimators: 1000, f1 score: 0.8653846153846154\n",
      "best n_estimators: 5\n",
      "best f1: 0.8694817658349328\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# tune coefficient c\n",
    "n_estimators_coef = np.geomspace(5, 1000, num=10). astype(int)\n",
    "print(f'tune n_estimators from {n_estimators_coef}')\n",
    "\n",
    "best_n_estimators = 5\n",
    "best_f1 = -np.inf\n",
    "for n_est in n_estimators_coef:\n",
    "    clf = RandomForestClassifier(n_estimators=n_est).fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_valid)\n",
    "    f1 = f1_score(y_valid, y_pred)\n",
    "    print(f'n_estimators: {n_est}, f1 score: {f1}')\n",
    "    \n",
    "    if f1 > best_f1:\n",
    "        best_c = c\n",
    "        best_f1 = f1\n",
    "print(f'best n_estimators: {best_n_estimators}')\n",
    "print(f'best f1: {best_f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 0.8204887218045113\n",
      "test precision: 0.7924901185770751\n",
      "test recall: 0.8234086242299795\n",
      "test f1_score: 0.8076535750251762\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "clf_randf = RandomForestClassifier(n_estimators=best_n_estimators).fit(x_train_valid, y_train_valid)\n",
    "y_pred = clf_randf.predict(x_test)\n",
    "print(f'test accuracy: {accuracy_score(y_test, y_pred)}')\n",
    "print(f'test precision: {precision_score(y_test, y_pred)}')\n",
    "print(f'test recall: {recall_score(y_test, y_pred)}')\n",
    "print(f'test f1_score: {f1_score(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 features with max absolute coefficient:\n",
      "翰 0.008074627065930299\n",
      "晴 0.008169650803155066\n",
      "柔 0.008216259271366795\n",
      "哲 0.008295568236742806\n",
      "芸 0.00835907112117001\n",
      "心 0.008420945891063566\n",
      "慈 0.008503364538537657\n",
      "佳 0.00855155795897566\n",
      "_Other_Feature_ 0.008631541391973998\n",
      "芷 0.008661924522415428\n",
      "庭 0.008764603378112547\n",
      "雅 0.00891694392430923\n",
      "承 0.009053493379566985\n",
      "蓁 0.009359105414781459\n",
      "怡 0.010542656942151602\n",
      "婷 0.013649445862693954\n",
      "萱 0.014016582532748808\n",
      "翔 0.01413261829872876\n",
      "柏 0.014500300227694015\n",
      "妤 0.019112038838368303\n"
     ]
    }
   ],
   "source": [
    "importance = clf_randf.feature_importances_\n",
    "max20 = importance.argsort()[-20:]\n",
    "print('20 features with max absolute coefficient:')\n",
    "for idx in max20:\n",
    "    print(x_test_col[idx], importance[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy, precision, recall, and f1-scores are all above 0.8. The prediction performs well.\n",
    "\n",
    "However, when it comes to the feature importance, it is not as intuitive as that of logistic regression. According to the official documentaion, \"impurity-based feature importances can be misleading for high cardinality features (many unique values)\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish fitting lr = 0.1\n",
      "finish fitting lr = 0.5\n",
      "finish fitting lr = 1\n",
      "lr = 0.1: best stage = 1002, best_f1_score = 0.9050279329608938\n",
      "lr = 0.5: best stage = 209, best_f1_score = 0.9004651162790698\n",
      "lr = 1: best stage = 198, best_f1_score = 0.8962264150943396\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# tune learning rate and n_estimator\n",
    "all_lr = [0.1, 0.5, 1]\n",
    "n_estimator = 1500\n",
    "\n",
    "best_stage = []\n",
    "best_f1 = []\n",
    "\n",
    "for lr in all_lr:\n",
    "    clf = GradientBoostingClassifier(n_estimators=n_estimator, learning_rate=lr).fit(x_train, y_train)\n",
    "    print(f'finish fitting lr = {lr}')\n",
    "    stages = list(range(n_estimator))\n",
    "    f1_scores = [0] * n_estimator\n",
    "    idx = 0\n",
    "    for stage, y_pred in enumerate(clf.staged_predict(x_valid)):\n",
    "        f1_scores[idx] = f1_score(y_valid, y_pred)\n",
    "        idx += 1\n",
    "    stages = np.array(stages)\n",
    "    f1_scores = np.array(f1_scores)\n",
    "    best_idx = np.argmax(f1_scores)\n",
    "    best_stage.append(stages[best_idx])\n",
    "    best_f1.append(f1_scores[best_idx])\n",
    "    plt.plot(stages, f1_scores, label=f'lr={lr}')\n",
    "\n",
    "for i in range(len(all_lr)):\n",
    "    print(f'lr = {all_lr[i]}: best stage = {best_stage[i]}, best_f1_score = {best_f1[i]}')\n",
    "plt.title('Gradient Boosting Classifier')\n",
    "plt.xlabel('stage')\n",
    "plt.ylabel('f1_score')    \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best lr = 0.1, best_nstg = 1002\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "best_f1 = np.array(best_f1)\n",
    "best_idx = np.argmax(best_f1)\n",
    "best_lr = all_lr[best_idx]\n",
    "best_nstg = best_stage[best_idx]\n",
    "print(f'best lr = {best_lr}, best_nstg = {best_nstg}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 0.8665413533834586\n",
      "test precision: 0.822429906542056\n",
      "test recall: 0.9034907597535934\n",
      "test f1_score: 0.8610567514677103\n"
     ]
    }
   ],
   "source": [
    "clf_gbdt = GradientBoostingClassifier(n_estimators=best_nstg, learning_rate=best_lr).fit(x_train_valid, y_train_valid)\n",
    "y_pred = clf_gbdt.predict(x_test)\n",
    "print(f'test accuracy: {accuracy_score(y_test, y_pred)}')\n",
    "print(f'test precision: {precision_score(y_test, y_pred)}')\n",
    "print(f'test recall: {recall_score(y_test, y_pred)}')\n",
    "print(f'test f1_score: {f1_score(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 features with max absolute coefficient:\n",
      "庭 0.010108165751030268\n",
      "慈 0.010148662080156226\n",
      "瑄 0.010457835251262015\n",
      "芷 0.010797252370754051\n",
      "涵 0.011112311838953073\n",
      "芸 0.011177614770121419\n",
      "宜 0.011331339834406597\n",
      "佳 0.011367081977882802\n",
      "柔 0.011610906994878045\n",
      "晴 0.011839408369194903\n",
      "雅 0.012133938145565442\n",
      "怡 0.01283586337557443\n",
      "蓁 0.012839459689449965\n",
      "承 0.012896883990426896\n",
      "哲 0.012957391865331246\n",
      "婷 0.01912972802235605\n",
      "柏 0.019957782960591277\n",
      "萱 0.020348411944513006\n",
      "翔 0.02291578885362541\n",
      "妤 0.030017040223587508\n"
     ]
    }
   ],
   "source": [
    "importance = clf_gbdt.feature_importances_\n",
    "max20 = importance.argsort()[-20:]\n",
    "print('20 features with max absolute coefficient:')\n",
    "for idx in max20:\n",
    "    print(x_test_col[idx], importance[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy, precision, recall, and f1-scores are all above 0.8. The prediction performs better than random forest.\n",
    "\n",
    "The top 20 important features seems reasonable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1073, 1) (1073, 1) (1073, 1)\n",
      "x_stack_meta shape = (1073, 3)\n"
     ]
    }
   ],
   "source": [
    "# get probability from base learners\n",
    "prob_logitic = clf_log.predict_proba(x_stack)[:, 1].reshape((-1, 1))\n",
    "prob_rand_forest = clf_randf.predict_proba(x_stack)[:, 1].reshape((-1, 1))\n",
    "prob_gbdt = clf_gbdt.predict_proba(x_stack)[:, 1].reshape((-1, 1))\n",
    "print(prob_logitic.shape, prob_rand_forest.shape, prob_gbdt.shape)\n",
    "x_stack_meta = np.concatenate((prob_logitic, prob_rand_forest, prob_gbdt), axis=1)\n",
    "print(f'x_stack_meta shape = {x_stack_meta.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_test_meta shape = (1064, 3)\n",
      "test accuracy: 0.8834586466165414\n",
      "test precision: 0.8579881656804734\n",
      "test recall: 0.893223819301848\n",
      "test f1_score: 0.8752515090543259\n"
     ]
    }
   ],
   "source": [
    "# meta learner\n",
    "clf_meta = LogisticRegression(penalty='none').fit(x_stack_meta, y_stack)\n",
    "test_prob_logitic = clf_log.predict_proba(x_test)[:, 1].reshape((-1, 1))\n",
    "test_prob_rand_forest = clf_randf.predict_proba(x_test)[:, 1].reshape((-1, 1))\n",
    "test_prob_gbdt = clf_gbdt.predict_proba(x_test)[:, 1].reshape((-1, 1))\n",
    "x_test_meta = np.concatenate((test_prob_logitic, test_prob_rand_forest, test_prob_gbdt), axis=1)\n",
    "print(f'x_test_meta shape = {x_test_meta.shape}')\n",
    "\n",
    "y_pred = clf_meta.predict(x_test_meta)\n",
    "\n",
    "print(f'test accuracy: {accuracy_score(y_test, y_pred)}')\n",
    "print(f'test precision: {precision_score(y_test, y_pred)}')\n",
    "print(f'test recall: {recall_score(y_test, y_pred)}')\n",
    "print(f'test f1_score: {f1_score(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.03596275 -0.39242928  5.50754097]]\n"
     ]
    }
   ],
   "source": [
    "# coefficient\n",
    "meta_coef = clf_meta.coef_\n",
    "print(meta_coef)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coefficient for probability from the logistic regression model, the random forest model, and the gradient boosting decision tree model are 3.036, -0.392, and 5.508, respectively.\n",
    "\n",
    "Note that the coefficient for probability from the gradient boosting decision tree is the largest. Meanwhile, it is the model that predicts the most accurately when standing alone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "stu_adm = pd.read_csv('ds/student_admission106.csv', encoding=\"utf-8\", dtype=str)\n",
    "uname = pd.read_csv('ds/univ_name106short1.csv', encoding=\"utf-8\", dtype=str)\n",
    "\n",
    "all_depid = stu_adm['department_id'].unique()\n",
    "all_stuid = stu_adm['student_id'].unique()\n",
    "\n",
    "ndepid = all_depid.shape[0]\n",
    "nstuid = all_stuid.shape[0]\n",
    "print(\"In raw data, there are %d students and %d departments in total.\" % (nstuid, ndepid))\n",
    "\n",
    "#construct the department-student matrix (i.e. array). \n",
    "dep_stu = np.zeros((ndepid, nstuid))\n",
    "rowname = all_depid.copy()\n",
    "\n",
    "depid_seq_map = dict()\n",
    "for i in range(ndepid):\n",
    "    depid_seq_map[all_depid[i]] = i\n",
    "\n",
    "stuid_seq_map = dict()\n",
    "for i in range(nstuid):\n",
    "    stuid_seq_map[all_stuid[i]] = i\n",
    "\n",
    "for cindex, row in stu_adm.iterrows():\n",
    "    #print(cindex, row)\n",
    "    dep_seq = depid_seq_map[row['department_id']]\n",
    "    stu_seq = stuid_seq_map[row['student_id']]\n",
    "    #print(dep_seq, stu_seq)\n",
    "    dep_stu[dep_seq, stu_seq] = 1\n",
    "\n",
    "# Remove very small departments.\n",
    "min_stu_per_dep = 10\n",
    "min_apply_dep_per_stu = 2\n",
    "\n",
    "# remove small departments and single-application students. \n",
    "dep_apply_sum = np.sum(dep_stu, axis = 1)\n",
    "keeprow = dep_apply_sum >= min_stu_per_dep\n",
    "rowname = rowname[keeprow]\n",
    "dep_stu2 = dep_stu[keeprow,:]\n",
    "stu_apply_sum = np.sum(dep_stu2, axis = 0)\n",
    "dep_stu2 = dep_stu2[:, stu_apply_sum >= min_apply_dep_per_stu]\n",
    "\n",
    "# another run of filtering\n",
    "dep_apply_sum = np.sum(dep_stu2, axis = 1)\n",
    "dep_stu2 = dep_stu2[dep_apply_sum >= min_stu_per_dep,:]\n",
    "rowname = rowname[dep_apply_sum >= min_stu_per_dep]\n",
    "stu_apply_sum = np.sum(dep_stu2, axis = 0)\n",
    "dep_stu2 = dep_stu2[:, stu_apply_sum >= min_apply_dep_per_stu]\n",
    "\n",
    "# third run of filtering\n",
    "dep_apply_sum = np.sum(dep_stu2, axis = 1)\n",
    "dep_stu2 = dep_stu2[dep_apply_sum >= min_stu_per_dep,:]\n",
    "rowname = rowname[dep_apply_sum >= min_stu_per_dep]\n",
    "\n",
    "stu_apply_sum = np.sum(dep_stu2, axis = 0)\n",
    "dep_stu2 = dep_stu2[:, stu_apply_sum >= min_apply_dep_per_stu]\n",
    "\n",
    "# check to make sure the two conditions are satisfied. \n",
    "dep_apply_sum = np.sum(dep_stu2, axis = 1)\n",
    "print(\"Number of department too small:\", np.sum(dep_apply_sum < min_stu_per_dep))\n",
    "stu_apply_sum = np.sum(dep_stu2, axis = 0)\n",
    "print(\"Number of students applying only one department:\", np.sum(stu_apply_sum <min_apply_dep_per_stu))\n",
    "\n",
    "# now both conditions are satisfied.\n",
    "\n",
    "uname['depname'] = uname.school_name_abbr + uname.department_name_abbr\n",
    "uname2 = uname[['department_id', 'depname', 'category_name']].copy()\n",
    "# this is for later use, to color data points. \n",
    "category_id, category_levels = pd.factorize(uname2.category_name)\n",
    "#uname2['category_id'] = category_id / np.max(category_id)\n",
    "uname2['category_id'] = category_id\n",
    "\n",
    "# create a data frame for column name\n",
    "colname_df = pd.DataFrame({'department_id': rowname})\n",
    "colname_df = colname_df.merge(uname2, how = \"left\", on=\"department_id\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
